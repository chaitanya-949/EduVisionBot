{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publication date of Smart City Surveillance Unveiling Indian Person Attributes in Real Time: Thu, 4 Jul 2024 (continued, showing 3 of 115 entries )\n",
      "Title: Smart City Surveillance Unveiling Indian Person Attributes in Real Time\n",
      "Authors of Smart City Surveillance Unveiling Indian Person Attributes in Real Time: Shubham Kale, Shashank Sharma, Abhilash Khuntia\n",
      "\n",
      "Smart City Surveillance Unveiling Indian Person\n",
      "Attributes in Real Time\n",
      "Shubham Kale\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "shubham23094@iiitd.ac.in\n",
      "Shashank Sharma\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "shashank23088@iiitd.ac.in\n",
      "Abhilash Khuntia\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "abhilash23007@iiitd.ac.in\n",
      "Abstract—This project focuses on creating a smart surveillance\n",
      "system for Indian cities that can identify and analyze people’s\n",
      "attributes in real time. Using advanced technologies like artificial\n",
      "intelligence and machine learning, the system can recognize\n",
      "attributes such as upper body color what the person is wearing,\n",
      "accessories that he or she is wearing, headgear check, etc.,\n",
      "and analyze behavior through cameras installed around the\n",
      "city. We have provided all our code for our experiments at\n",
      "https://github.com/abhilashk23/vehant-scs-par We will be contin-\n",
      "uously updating the above GitHub repo to keep up-to-date with\n",
      "the most cutting-edge work on person attribute recognition.\n",
      "I. INTRODUCTION\n",
      "In today’s rapidly developing world, ensuring the safety and\n",
      "security of citizens has become a concern for city administra-\n",
      "tors. The project ”Smart City Surveillance Unveiling Indian\n",
      "Person Attributes in Real Time” addresses this challenge\n",
      "by harnessing the power of artificial intelligence (AI) and\n",
      "machine learning (ML) to create a cutting-edge surveillance\n",
      "system. This system is tailored specifically for Indian cities,\n",
      "where diverse populations and bustling urban environments\n",
      "necessitate innovative solutions [27] [3] [13].\n",
      "The primary objective of this project is to deploy a network\n",
      "of intelligent cameras with computer vision models capable\n",
      "of not only monitoring, but also comprehensively analyzing\n",
      "individual attributes in real time. These attributes include\n",
      "but are not limited to upper body colors, clothing styles,\n",
      "accessories, and various types of headgear worn by individuals\n",
      "[30] [8]. By leveraging AI algorithms, the system can detect\n",
      "anomalies, identify suspicious behavior patterns, and provide\n",
      "timely alerts to law enforcement agencies [24] [1].\n",
      "Moreover, the project emphasizes the importance of pri-\n",
      "vacy and ethical considerations in the deployment of surveil-\n",
      "lance technologies [16]. Robust measures are implemented\n",
      "to ensure data protection, adherence to legal regulations, and\n",
      "transparency in operations [5] [21]. Public engagement and\n",
      "feedback mechanisms are also integral, fostering community\n",
      "trust and collaboration in enhancing urban safety [26] [12].\n",
      "By integrating advanced data analytics and predictive mod-\n",
      "eling, the system aims to not only mitigate security risks but\n",
      "also optimize urban planning and resource management [35]\n",
      "[33]. Insights derived from real-time surveillance data can in-\n",
      "form city planners about crowd dynamics, traffic patterns, and\n",
      "public infrastructure usage, thereby facilitating more efficient\n",
      "city operations [31] [17].\n",
      "Ultimately, ”Smart City Surveillance Unveiling Indian Per-\n",
      "son Attributes in Real Time” endeavors to set a benchmark\n",
      "for smart city initiatives, demonstrating how AI-driven tech-\n",
      "nologies can contribute to creating safer, more resilient, and\n",
      "inclusive urban environments in India [28] [29].\n",
      "II. DATASET\n",
      "The dataset provided for the VEHANT RESEARCH LAB\n",
      "challenge on ’Smart City Surveillance: Unveiling Indian Per-\n",
      "son Attributes in Real Time consists of around 600 images\n",
      "categorized under various attributes [19]. These attributes\n",
      "encompass a variety of visual features, including colors and\n",
      "types of upper and lower body clothing, length of sleeves, ac-\n",
      "cessories carried, types of footwear, poses, and views [30] [8].\n",
      "Data augmentation is crucial for computer vision tasks where\n",
      "the dataset for a particular task is very low, so in this case,\n",
      "we can perform various data augmentation techniques which\n",
      "can help to upsample the dataset, thus building a more robust\n",
      "model [18] [22] [32]. For the person attribute recognition task,\n",
      "we have used different augmentation techniques, which will\n",
      "help in up-sampling the dataset [40] [25].. The techniques used\n",
      "were:\n",
      "Parameter\n",
      "Value\n",
      "Rotation Range\n",
      "±25 degrees\n",
      "Width Shift Range\n",
      "±15% of the total width\n",
      "Height Shift Range\n",
      "±15% of the total height\n",
      "Shear Range\n",
      "0.5 intensity\n",
      "Zoom Range\n",
      "±50%\n",
      "Horizontal Flip\n",
      "Random horizontal flip\n",
      "Fill Mode\n",
      "’nearest’\n",
      "TABLE I\n",
      "DATA AUGMENTATION PARAMETERS\n",
      "III. METHODOLOGY\n",
      "In our experiment, we used data augmentation techniques to\n",
      "expand our dataset. Initially, we had 600 images. Each image\n",
      "was augmented 12 times, considerably increasing the number\n",
      "of samples for training our model [32] [25].\n",
      "arXiv:2407.03305v1  [cs.CV]  3 Jul 2024\n",
      "Data augmentation is a crucial strategy that is used to\n",
      "increase the diversity of our training data set without collect-\n",
      "ing new data. By applying transformations such as rotation,\n",
      "scaling, and flipping, we created new images from the original\n",
      "set, thus enhancing the robustness of our model [38] [37].\n",
      "Fig. 1. Model Architecture and flow of the project\n",
      "To ensure our model was evaluated effectively, we split the\n",
      "augmented dataset into training and validation sets. We applied\n",
      "an 80-20 split, where 20% of the data was used for validation.\n",
      "This means that out of the total number of augmented images,\n",
      "80% was used to train the model, and 20% was used to validate\n",
      "it [7].\n",
      "A. First Approach :\n",
      "For person attribute recognition, we used the BEiT (Bidi-\n",
      "rectional Encoder representation from Image Transformers)\n",
      "model optimized for person attribute recognition [2]. The train-\n",
      "ing pipeline included data preparation, model initialization,\n",
      "training, and validation. Augmented images and their labels\n",
      "were loaded using PyTorch DataLoader for efficient batch\n",
      "processing [23]. The BEiT model and image processor were\n",
      "initialized with the HuggingFace transformers library\n",
      "[36]. Training was conducted for fifteen epochs with the Adam\n",
      "optimizer at a learning rate of 1 × 10−5, using Binary Cross\n",
      "Entropy with Logits Loss [14]. A custom callback calculated\n",
      "label-based mean accuracy (mA) at each epoch’s end. The\n",
      "model’s performance was evaluated on the validation set, and\n",
      "the model with the lowest validation loss was retained for\n",
      "further testing. figure 1 shows the flow of the project.\n",
      "B. Second Approach :\n",
      "In our second approach, we leveraged cutting-edge deep\n",
      "learning algorithms to classify images using the Swin Trans-\n",
      "former architecture [20]. We used the same augmentation\n",
      "techniques as in our previous strategy, and we used PyTorch’s\n",
      "Dataset and DataLoader utilities to manage data loading with a\n",
      "custom ImageDataset class [23]. The Swin Transformer, which\n",
      "is well-known for its state-of-the-art performance, was chosen\n",
      "and customised for our goal using the pre-trained SwinForIm-\n",
      "ageClassification model from the transformers library, which\n",
      "was trained on ImageNet [6] [15]. The model’s compatibility\n",
      "was ensured by using AutoImageProcessor for preprocessing.\n",
      "Each of the 15 epochs used for training included separate steps\n",
      "for validation and training. After inputting the images into the\n",
      "GPU for training, predictions were generated, and the loss\n",
      "was computed using BCEWithLogitsLoss [7]. Subsequently,\n",
      "the model parameters were fine-tuned using the Adam op-\n",
      "timizer [14]. The training and validation processes involved\n",
      "monitoring two key performance indicators (KPIs): accuracy\n",
      "and loss [4].\n",
      "C. Challenges with Initial Approaches\n",
      "1) Overfitting: The first two approaches to person attribute\n",
      "recognition faced significant overfitting issues. Overfitting\n",
      "occurs when a model performs well on the training data but\n",
      "poorly on unseen validation or test data [10]. This typically\n",
      "happens when the model learns to memorize the training data\n",
      "rather than generalizing from it. Overfitting can be mitigated\n",
      "by using techniques such as data augmentation, regularization\n",
      "(e.g., dropout), and cross-validation [34].\n",
      "2) Computationally Intensive: The initial models were also\n",
      "computationally intensive, which means they required a sig-\n",
      "nificant amount of computational resources (GPU) and time\n",
      "to train [4]. This can be due to various factors, such as:\n",
      "• Large model size with many parameters [7].\n",
      "• Inefficient data loading and preprocessing [23].\n",
      "To address these issues, we went through third approach below\n",
      "[9].\n",
      "D. Third Approach :\n",
      "In the initial approach, we faced issues with class imbalance\n",
      "and overfitting. To overcome these, we include the Scaled-\n",
      "BCELoss and FeatClassifier in this approach. The ”Scaled-\n",
      "BCELoss” fixes class imbalance by adjusting the weights\n",
      "of different attribute classes. This makes sure that learning\n",
      "from both common and rare attributes works well, which\n",
      "leads to better generalization and performance on data that\n",
      "has not been seen before [39]. The FeatClassifier combines\n",
      "a pre-trained ResNet50 backbone with a custom classifier\n",
      "head, leveraging robust feature extraction and tailored attribute\n",
      "mapping. This enhances model accuracy and efficiency, and\n",
      "dropout regularization prevents overfitting, resulting in a more\n",
      "reliable performance on person attribute recognition model\n",
      "[11] [34].\n",
      "1. ScaledBCELoss\n",
      "The ScaledBCELoss class implements a custom binary\n",
      "cross-entropy loss function that scales the logits based on the\n",
      "frequency of each class in the dataset. This helps in balancing\n",
      "the contribution of frequent and infrequent person attributes\n",
      "to the loss, which is particularly useful in cases of class\n",
      "imbalance [39].\n",
      "2. FeatClassifier\n",
      "The FeatClassifier class combines a feature extractor back-\n",
      "bone (in this case, a ResNet50 model pre-trained on ImageNet)\n",
      "with a custom classifier head. The backbone extracts high-\n",
      "level features from the input images, and the classifier head\n",
      "(a fully connected layer) maps these features to the output\n",
      "classes (person attributes) [11].\n",
      "3. Training and Evaluation\n",
      "The train and evaluate function orchestrates the entire\n",
      "training and evaluation process. It includes:\n",
      "• Data loading and transformation using DataLoader [23].\n",
      "• Model initialization with a pre-trained ResNet50 back-\n",
      "bone [11].\n",
      "• Loading pre-trained weights for fine-tuning [7].\n",
      "• Defining the optimizer and learning rate scheduler [14].\n",
      "• Training loop with model evaluation on the validation set\n",
      "[10].\n",
      "• Saving the best model based on validation accuracy [4].\n",
      "IV. CHALLENGES\n",
      "In the Smart City Surveillance project, designed to unveil In-\n",
      "dian person attributes in real time, we faced several significant\n",
      "challenges that affected the model’s performance. A primary\n",
      "issue was the scarcity of training images, which constrained\n",
      "the model’s ability to learn and generalize effectively across\n",
      "various attributes. This limitation was particularly evident in\n",
      "the model’s difficulty in recognizing specific attributes such as\n",
      "shoes and items carried by individuals. The inadequate dataset\n",
      "for these attributes meant the model struggled to identify and\n",
      "categorize them accurately.\n",
      "Moreover, there was a noticeable performance discrep-\n",
      "ancy between the static model and its real-time counterpart.\n",
      "While the static model performed admirably under controlled\n",
      "conditions, its accuracy and reliability significantly dropped\n",
      "when deployed in real-time scenarios. This gap highlighted\n",
      "the model’s struggle to adapt to the dynamic nature of real-\n",
      "time surveillance, which involves constantly changing lighting\n",
      "conditions, occlusions where parts of a person may be blocked\n",
      "from view, and rapid movements. These real-world complex-\n",
      "ities presented substantial challenges that the model was not\n",
      "fully equipped to handle.\n",
      "The deployment phase also revealed that the model robust-\n",
      "ness needed improvement to achieve consistent performance\n",
      "in real-time applications. This includes refining the model\n",
      "architecture, enhancing its ability to process and analyze\n",
      "live video feeds, and implementing strategies to handle the\n",
      "variability and unpredictability of real-world environments.\n",
      "In summary, while the project has made significant progress\n",
      "in developing a surveillance system capable of identifying\n",
      "person attributes in real time, it faces ongoing challenges that\n",
      "require further research and development. Addressing these\n",
      "challenges through data augmentation, advanced techniques,\n",
      "and model refinement will be key to achieving a more accurate\n",
      "and reliable real-time surveillance system.\n",
      "V. SCOPE OF IMPROVEMENT\n",
      "1) Dataset Expansion and Diversification:\n",
      "• Increase Quantity and Diversity: Acquiring a larger\n",
      "and more diverse set of training images is crucial. This\n",
      "includes capturing various scenarios, lighting condi-\n",
      "tions, and different types of footwear and carried items.\n",
      "A diverse dataset will help the model generalize better\n",
      "and improve accuracy across various attributes.\n",
      "• Synthetic Data Generation: Using techniques such\n",
      "as data augmentation and synthetic data generation\n",
      "can help simulate different scenarios and augment the\n",
      "existing dataset. This approach can provide the model\n",
      "with more examples to learn from without the need for\n",
      "extensive manual data collection.\n",
      "2) Advanced Machine Learning Techniques:\n",
      "• Transfer Learning: Implementing transfer learning\n",
      "can enhance the model’s performance by leveraging\n",
      "pre-trained models on large, diverse datasets. This can\n",
      "help the model learn more effectively from the limited\n",
      "data available and improve its ability to recognize\n",
      "specific attributes.\n",
      "• Fine-Tuning: Continuously fine-tuning the model with\n",
      "new data and incorporating feedback from real-time\n",
      "deployments can help adapt the model to changing\n",
      "conditions and improve its accuracy over time.\n",
      "3) Model Architecture and Optimization:\n",
      "• Improved Architecture: Experimenting with\n",
      "different model architectures and incorporating\n",
      "state-of-the-art techniques can enhance the model’s\n",
      "robustness and accuracy. Techniques like attention\n",
      "mechanisms and convolutional neural networks\n",
      "(CNNs) can be explored to better capture and\n",
      "recognize fine-grained details.\n",
      "• Optimization for Real-Time Performance:\n",
      "Optimizing the model for real-time performance\n",
      "involves reducing latency and improving\n",
      "computational efficiency. Techniques such as model\n",
      "pruning, quantization, and using efficient neural\n",
      "network architectures can help achieve faster and\n",
      "more reliable real-time processing.\n",
      "4) Real-Time Adaptability and Robustness:\n",
      "• Handling Variability: Developing algorithms that\n",
      "can handle variability in real-time conditions, such as\n",
      "changes in lighting, occlusions, and rapid movements,\n",
      "is essential. This may involve incorporating adaptive\n",
      "algorithms that can dynamically adjust to changing\n",
      "environments.\n",
      "• Continuous Learning: Implementing continuous\n",
      "learning frameworks where the model can learn from\n",
      "new data and experiences in real-time can help\n",
      "improve its adaptability and robustness. This includes\n",
      "using techniques like online learning and\n",
      "reinforcement learning.\n",
      "5) Integration with Additional Sensors and Data Sources:\n",
      "• Multi-Modal Data Integration: Integrating data\n",
      "from additional sensors, such as depth cameras,\n",
      "thermal cameras, and audio sensors, can provide\n",
      "complementary information that enhances the model’s\n",
      "ability to recognize and understand person attributes.\n",
      "• Contextual Information: Incorporating contextual\n",
      "information, such as location data, time of day, and\n",
      "historical patterns, can help improve the model’s\n",
      "accuracy and provide more meaningful insights.\n",
      "6) User Interface and Experience:\n",
      "• Enhanced GUI: Improving the graphical user\n",
      "interface (GUI) to be more intuitive and user-friendly\n",
      "can facilitate easier interaction with the system.\n",
      "Features like real-time alerts, detailed analytics, and\n",
      "customization options can enhance the user\n",
      "experience.\n",
      "• Feedback Mechanisms: Implementing feedback\n",
      "mechanisms where users can provide input on the\n",
      "model’s performance and flag inaccuracies can help\n",
      "continuously refine and improve the model.\n",
      "VI. EXPERIMENTAL RESULTS\n",
      "Sr.No\n",
      "Model\n",
      "mA Val\n",
      "Train Loss\n",
      "Val Loss\n",
      "Epoch\n",
      "1\n",
      "Model 1\n",
      "0.91\n",
      "0.008\n",
      "0.32\n",
      "15\n",
      "2\n",
      "Model 2\n",
      "0.91\n",
      "0.003\n",
      "0.38\n",
      "15\n",
      "3\n",
      "Model 3\n",
      "0.86\n",
      "0.14\n",
      "0.17\n",
      "15\n",
      "TABLE II\n",
      "COMPARISON OF DIFFERENT MODELS\n",
      "VII. RESOURCE UTILIZATION\n",
      "Model\n",
      "Computation Time (seconds)\n",
      "Device Type\n",
      "Model 1\n",
      "52214.74\n",
      "GPU P100\n",
      "Model 2\n",
      "52327.79\n",
      "GPU P100\n",
      "Model 3\n",
      "1020.65\n",
      "GPU P100\n",
      "TABLE III\n",
      "RESOURCE UTILIZATION BY DIFFERENT MODELS\n",
      "VIII. VISUALIZATION\n",
      "Fig. 2. Train & Validation Loss Vs Epoch model 1\n",
      "Fig. 3. Train & Validation Loss Vs Epoch model 2\n",
      "Fig. 4. Train & Validation Loss Vs Epoch model 3\n",
      "IX. FUTURE WORK\n",
      "In the landscape of urban development, smart city surveil-\n",
      "lance stands poised at the forefront of innovation, promising\n",
      "transformative advancements in safety, efficiency, and com-\n",
      "munity participation. As cities embrace interconnected tech-\n",
      "nologies and data-driven solutions, the future of work within\n",
      "smart city surveillance unfolds with distinct implications and\n",
      "opportunities.\n",
      "• Public Health Monitoring:\n",
      "– Epidemic Surveillance: In public areas, surveillance\n",
      "devices can keep an eye on things like body tem-\n",
      "perature, movement patterns, and crowd density. This\n",
      "data can be analyzed to detect early signs of disease\n",
      "outbreaks, allowing for prompt public health responses\n",
      "and containment measures.\n",
      "– Behavioral Analysis: Authorities can act swiftly and\n",
      "efficiently by recognising odd behaviours or trends that\n",
      "may point to emergencies or health threats by analysing\n",
      "data from monitoring systems.\n",
      "• Community Engagement:\n",
      "– Transparency: In order to interact with the public, cities\n",
      "should be transparent about the data that is gathered,\n",
      "how it is used, and how surveillance technologies work.\n",
      "Policies that are transparent foster confidence and\n",
      "reassure the public about the appropriate application\n",
      "of surveillance technologies.\n",
      "– Education and Participation: Community support and\n",
      "cooperation are fostered by informing the public about\n",
      "the advantages of smart city surveillance, such as\n",
      "increased safety and better urban services, and by\n",
      "offering channels for public feedback and involvement\n",
      "in decision-making processes.\n",
      "• Crisis Response and Management:\n",
      "– Social Media Integration: By combining social media\n",
      "analytics with surveillance data, authorities can better\n",
      "assess public opinion during emergencies and respond\n",
      "to community needs.\n",
      "– Drone Surveillance: Deploying drones with surveil-\n",
      "lance capabilities to quickly analyze the situation from\n",
      "the air during crises like fires, natural catastrophes, or\n",
      "search and rescue missions.\n",
      "X. MODEL DEPLOYMENT\n",
      "We have created a GUI using the model in our third\n",
      "approach -\n",
      "1) Live camera prediction: Created a GUI using Tkinter\n",
      "which uses the device cam to give live predictions for\n",
      "the labels Figure 5 & 6. The demo is shown below. The\n",
      "image shown in figure 7 depicts our setup Live demo\n",
      "link..\n",
      "Fig. 5. Live Prediction 1\n",
      "Fig. 6. Live Prediction 2\n",
      "2) Static Prediction: We deployed our model on Hugging\n",
      "Face and developed a GUI that enables users to upload\n",
      "Fig. 7. Our setup for live prediction\n",
      "images and receive predictions from our model in figure\n",
      "8. Here is the demo link.\n",
      "Fig. 8. Static Prediction 1\n",
      "XI. CONCLUSION\n",
      "In this study, we developed a comprehensive pipeline\n",
      "for person attribute recognition, evaluating three distinct ap-\n",
      "proaches: BEiT, SWIN, and FeatClassifier. Our initial ex-\n",
      "periments with the BEiT model incorporated advanced data\n",
      "augmentation techniques and a novel ScaledBCELoss function\n",
      "to address class imbalance. We then explored the SWIN model,\n",
      "a state-of-the-art architecture renowned for its performance\n",
      "in various vision tasks. However, the FeatClassifier, which\n",
      "integrates a pre-trained ResNet50 backbone with a custom\n",
      "classifier head, emerged as the most effective model. Its\n",
      "superior performance can be attributed to dropout regulariza-\n",
      "tion that successfully mitigates overfitting and its pre-training\n",
      "on the RAPv2 dataset, which is specifically comprised of\n",
      "pedestrian images. In contrast, the BEiT and SWIN models\n",
      "were pre-trained on the ImageNet dataset, which contains a\n",
      "diverse range of images.\n",
      "Our experimental results validate the FeatClassifier ap-\n",
      "proach, demonstrating its strong potential for real-world ap-\n",
      "plications in person attribute recognition. Moving forward, we\n",
      "are excited about further enhancing our pipeline. Future work\n",
      "will involve implementing more sophisticated augmentation\n",
      "strategies, experimenting with various backbone architectures,\n",
      "and extending our model to recognize a wider array of\n",
      "attributes. Additionally, we plan to test our approach on larger\n",
      "and more diverse datasets to further confirm its robustness\n",
      "and scalability. We are committed to advancing this project\n",
      "and look forward to achieving even greater milestones in the\n",
      "field of person attribute recognition.\n",
      "REFERENCES\n",
      "[1] S Agarwal. Anomaly detection in surveillance. Security Journal, pages\n",
      "98–108, 2020.\n",
      "[2] H Bao, L Dong, and F Wei. Beit: Bert pre-training of image transform-\n",
      "ers. arXiv preprint arXiv:2106.08254, pages 1–13, 2021.\n",
      "[3] R Bhargava and S Jain. Ml techniques in urban planning. Urban Science,\n",
      "pages 112–121, 2019.\n",
      "[4] J Brownlee. Accuracy and performance in deep learning. Deep Learning\n",
      "Journal, pages 15–25, 2019.\n",
      "[5] S Das and V Rao. Legal regulations in ai surveillance. Law Journal,\n",
      "pages 40–50, 2021.\n",
      "[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-\n",
      "Fei. Imagenet: A large-scale hierarchical image database. 2009 IEEE\n",
      "Conference on Computer Vision and Pattern Recognition, pages 248–\n",
      "255, 2009.\n",
      "[7] I Goodfellow, Y Bengio, and A Courville. Deep learning. MIT Press,\n",
      "pages 1–775, 2016.\n",
      "[8] N Gupta and A Patel. Use of accessories in urban areas. Accessory\n",
      "Review, pages 23–34, 2019.\n",
      "[9] Song Han, Jeff Pool, John Tran, and William Dally.\n",
      "Deep learning.\n",
      "arXiv preprint arXiv:1506.02626, pages 1–10, 2015.\n",
      "[10] T Hastie, R Tibshirani, and J Friedman.\n",
      "The elements of statistical\n",
      "learning. Springer, pages 1–745, 2009.\n",
      "[11] K He, X Zhang, S Ren, and J Sun. Deep residual learning for image\n",
      "recognition. Proceedings of the IEEE Conference on Computer Vision\n",
      "and Pattern Recognition, pages 770–778, 2016.\n",
      "[12] A Jain. Community trust in ai. Community Journal, pages 34–45, 2019.\n",
      "[13] M Khan. Diversity in indian cities. Cultural Studies, pages 15–26, 2021.\n",
      "[14] DP Kingma and J Ba. Adam: A method for stochastic optimization.\n",
      "arXiv preprint arXiv:1412.6980, pages 1–15, 2014.\n",
      "[15] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\n",
      "Imagenet\n",
      "classification with deep convolutional neural networks.\n",
      "Advances in\n",
      "neural information processing systems, 25:1097–1105, 2012.\n",
      "[16] P Kulkarni. Privacy concerns in ai. AI Ethics, pages 12–23, 2022.\n",
      "[17] A Kumar and D Patel. Traffic patterns in cities. Traffic Journal, pages\n",
      "45–55, 2019.\n",
      "[18] R Kumar and P Mehta. Image data augmentation approaches. Journal\n",
      "of Computer Vision, pages 78–89, 2023.\n",
      "[19] Vehant Research Lab. Vehant research lab challenge dataset. Research\n",
      "Lab Data, pages 10–20, 2021.\n",
      "[20] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang,\n",
      "Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision\n",
      "transformer using shifted windows.\n",
      "Proceedings of the IEEE/CVF\n",
      "International Conference on Computer Vision (ICCV), pages 10012–\n",
      "10022, 2021.\n",
      "[21] K Mehta and P Shah. Transparency in ai systems. Tech Ethics, pages\n",
      "30–42, 2021.\n",
      "[22] S Mir. Data augmentation techniques for computer vision. Journal of\n",
      "AI Research, pages 123–134, 2022.\n",
      "[23] A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen,\n",
      "Z Lin, N Gimelshein, L Antiga, et al. Pytorch: An imperative style,\n",
      "high-performance deep learning library. Advances in Neural Information\n",
      "Processing Systems, pages 1–12, 2019.\n",
      "[24] V Patil and P Deshmukh. Surveillance in smart cities. Surveillance\n",
      "Review, pages 78–88, 2021.\n",
      "[25] L Perez and J Wang.\n",
      "The effectiveness of data augmentation in\n",
      "image classification using deep learning. Journal of Machine Learning\n",
      "Research, pages 1–20, 2017.\n",
      "[26] R Ramesh and A Verma. Public engagement in smart cities. Urban\n",
      "Affairs, pages 78–89, 2020.\n",
      "[27] A Rao and M Srivastava.\n",
      "Ai in smart cities.\n",
      "Journal of Urban\n",
      "Technology, pages 35–45, 2018.\n",
      "[28] B Reddy. Ai in urban development. Urban AI, pages 33–44, 2021.\n",
      "[29] M Shah and K Desai. Smart city technologies. Smart City Journal,\n",
      "pages 15–25, 2022.\n",
      "[30] A Sharma and R Gupta. Fashion trends in urban india. Fashion Journal,\n",
      "pages 50–60, 2020.\n",
      "[31] N Sharma.\n",
      "Crowd dynamics in urban areas.\n",
      "Crowd Science, pages\n",
      "20–30, 2018.\n",
      "[32] C Shorten and TM Khoshgoftaar. A survey on image data augmentation\n",
      "for deep learning. Journal of Big Data, pages 1–48, 2019.\n",
      "[33] P Singh. Urban resource management. Resource Management, pages\n",
      "55–65, 2020.\n",
      "[34] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever,\n",
      "and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural\n",
      "networks from overfitting. Journal of Machine Learning Research, pages\n",
      "1929–1958, 2014.\n",
      "[35] R Venkat. Data analytics in urban planning. Analytics Journal, pages\n",
      "89–99, 2022.\n",
      "[36] T Wolf, L Debut, V Sanh, J Chaumond, C Delangue, A Moi, P Cistac,\n",
      "T Rault, R Louf, M Funtowicz, et al.\n",
      "Transformers: State-of-the-art\n",
      "natural language processing. Proceedings of the 2020 Conference on\n",
      "Empirical Methods in Natural Language Processing: System Demon-\n",
      "strations, pages 38–45, 2020.\n",
      "[37] S Yun, D Han, S Oh, S Chun, J Choe, and Y Yoo. Cutmix: Regu-\n",
      "larization strategy to train strong classifiers with localizable features.\n",
      "International Conference on Computer Vision, pages 1–10, 2019.\n",
      "[38] H Zhang, M Cisse, Y Dauphin, and D Lopez-Paz.\n",
      "Mixup: Beyond\n",
      "empirical risk minimization.\n",
      "International Conference on Learning\n",
      "Representations, pages 1–13, 2018.\n",
      "[39] Z Zhang.\n",
      "Imbalanced classification of images.\n",
      "Journal of Machine\n",
      "Learning Research, pages 45–60, 2018.\n",
      "[40] Y Zhu and L Wang. Data augmentation for object detection. IEEE\n",
      "Transactions on Image Processing, pages 10–20, 2020.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "publication date of Improved Noise Schedule for Diffusion Training: Thu, 4 Jul 2024 (continued, showing 3 of 115 entries )\n",
      "Title: Improved Noise Schedule for Diffusion Training\n",
      "Authors of Improved Noise Schedule for Diffusion Training: Tiankai Hang, Shuyang Gu\n",
      "\n",
      "Technical Report\n",
      "IMPROVED NOISE SCHEDULE FOR DIFFUSION TRAIN-\n",
      "ING\n",
      "Tiankai Hang∗\n",
      "Southeast University\n",
      "tkhang@seu.edu.cn\n",
      "Shuyang Gu\n",
      "Microsoft Research Asia\n",
      "shuyanggu@microsoft.com\n",
      "ABSTRACT\n",
      "Diffusion models have emerged as the de facto choice for generating visual sig-\n",
      "nals. However, training a single model to predict noise across various levels poses\n",
      "significant challenges, necessitating numerous iterations and incurring significant\n",
      "computational costs. Various approaches, such as loss weighting strategy design\n",
      "and architectural refinements, have been introduced to expedite convergence. In\n",
      "this study, we propose a novel approach to design the noise schedule for enhancing\n",
      "the training of diffusion models. Our key insight is that the importance sampling\n",
      "of the logarithm of the Signal-to-Noise ratio (log SNR), theoretically equivalent to\n",
      "a modified noise schedule, is particularly beneficial for training efficiency when\n",
      "increasing the sample frequency around log SNR = 0. We empirically demon-\n",
      "strate the superiority of our noise schedule over the standard cosine schedule.\n",
      "Furthermore, we highlight the advantages of our noise schedule design on the\n",
      "ImageNet benchmark, showing that the designed schedule consistently benefits\n",
      "different prediction targets.\n",
      "1\n",
      "INTRODUCTION\n",
      "Diffusion models have emerged as a pivotal technique for generating visual signals across diverse\n",
      "domains, such as image synthesis (Ramesh et al., 2022; Saharia et al., 2022; Rombach et al., 2022)\n",
      "and video generation (Brooks et al., 2024). They are particularly adept at approximating complex\n",
      "distributions, where Generative Adversarial Networks (GANs) may encounter difficulties. Despite\n",
      "the substantial computational resources and numerous training iterations required for convergence,\n",
      "improving the training efficiency of diffusion models is essential for their application in large-scale\n",
      "scenarios, such as high-resolution image synthesis and video generation.\n",
      "Architectural enhancements offer a promising path to improve both the training speed and perfor-\n",
      "mance of diffusion models. For instance, the use of Adaptive Layer Normalization (Gu et al., 2022),\n",
      "when combined with zero initialization in the Transformer architecture as demonstrated by Peebles\n",
      "& Xie (2023), represents such an improvement. Similarly, the adoption of U-shaped skip connec-\n",
      "tions within Transformers, as outlined in previous works (Hoogeboom et al., 2023; Bao et al., 2022;\n",
      "Crowson et al., 2024), also boosts efficiency. In a parallel development, Karras et al. (2024) have\n",
      "contributed to this endeavor by reengineering the layers of ADM UNet (Dhariwal & Nichol, 2021)\n",
      "to preserve the magnitudes of activations, weights, and updates, ensuring a more efficient learning\n",
      "process.\n",
      "Concurrently, various loss weighting designs have been implemented to accelerate the convergence\n",
      "of training. Previous works, such as eDiff-I (Balaji et al., 2022) and Min-SNR (Hang et al., 2023),\n",
      "found that the training of diffusion models may encounter conflicts among various noise intensities.\n",
      "Choi et al. (2022) prioritize specific noise levels during training to enhance learning of visual con-\n",
      "cepts. Min-SNR (Hang et al., 2023) reduces weights of noisy tasks, pursuing the Pareto Optimality\n",
      "in different denoising tasks, validated its effectiveness on multiple datasets and architectures. A\n",
      "softer version of this approach, aiming to further enhance high-resolution image synthesis within\n",
      "hourglass diffusion models, was introduced by Crowson et al. (2024). SD3 (Esser et al., 2024) em-\n",
      "pirically found that it’s crucial to increase the weight of the intermediate noise intensities, which has\n",
      "demonstrated the effectiveness during training the diffusion models.\n",
      "∗Long-term researcher intern at Microsoft Research Asia.\n",
      "1\n",
      "arXiv:2407.03297v1  [cs.CV]  3 Jul 2024\n",
      "Technical Report\n",
      "−20\n",
      "−15\n",
      "−10\n",
      "−5\n",
      "0\n",
      "5\n",
      "10\n",
      "λ = log SNR\n",
      "0.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "p(λ)\n",
      "Cosine: sech(λ/2)/(2π)\n",
      "Cosine Scaled: s · sech(λs/2)/(2π), s = 2\n",
      "Cosine Shifted: sech(λ/2 −s)/(2π), s = −3\n",
      "Laplace:\n",
      "1\n",
      "2b exp(−|λ −µ|/b), µ = 0, b = 1\n",
      "Cauchy:\n",
      "1\n",
      "π\n",
      "γ\n",
      "γ2+(λ−λ0)2 , γ = 1, λ0 = 3\n",
      "Figure 1: Illustration of the probability density functions of different noise schedules.\n",
      "In this study, we present a novel method to enhance the training of diffusion models by strategi-\n",
      "cally redefining the noise schedule, which is equivalent to importance sampling of the noise across\n",
      "different intensities. However, empirical evidence suggests that allocating more computation costs\n",
      "(FLOPs) to mid-range noise levels (around log SNR = 0) yields superior performance compared to\n",
      "increasing loss weights during the same period, particularly under constrained computational bud-\n",
      "gets. We experimentally analyze the performance of several different noise schedules, including\n",
      "Laplace, Cauchy, and the Cosine Shifted/Scaled, which are visualized in Figure 1. Notably, the\n",
      "Laplace schedule exhibits favorable performance. We recommend to choose this noise schedule in\n",
      "the future.\n",
      "We demonstrate the effectiveness of this approach using the ImageNet benchmark, with a consistent\n",
      "training budget of 500K iterations. Evaluated using the FID metric, our results reveal that noise\n",
      "schedules with a concentrated probability density around log SNR = 0 consistently surpass others,\n",
      "as evidenced at both 256 × 256 and 512 × 512 resolutions with different prediction target. This\n",
      "research contributes to the advancement of efficient training techniques for diffusion models.\n",
      "2\n",
      "METHOD\n",
      "2.1\n",
      "PRELIMINARIES\n",
      "Diffusion models (Ho et al., 2020; Yang et al., 2021) learn to generate data by iteratively reversing\n",
      "the diffusion process. We denote the distribution of data points as x ∼pdata(x). The diffusion\n",
      "process progressively adds noise to the data, which is defined as:\n",
      "xt = αtx + σtϵ,\n",
      "where\n",
      "ϵ ∼N(0, I),\n",
      "(1)\n",
      "where αt and σt are the coefficients of the adding noise process, essentially representing the noise\n",
      "schedule. For the commonly used prediction target velocity: vt = αtϵ −σtx (Salimans & Ho,\n",
      "2022), the diffusion model θ is trained through the Mean Squared Error (MSE) loss:\n",
      "L(θ) = Ex∼pdata(x)Et∼p(t)\n",
      "\u0002\n",
      "w(t)∥vθ(αtx + σtϵ, t, c) −vt∥2\n",
      "2\n",
      "\u0003\n",
      ",\n",
      "(2)\n",
      "where w(t) is the loss weight, c denotes the condition information. Common practices sample t\n",
      "from the uniform distribution U[0, 1]. Kingma et al. (2021) introduced the Signal-to-Noise ratio as\n",
      "SNR(t) = α2\n",
      "t\n",
      "σ2\n",
      "t to measure the noise level of different states. To simplify, we denote λ = log SNR to\n",
      "2\n",
      "Technical Report\n",
      "Noise Schedule\n",
      "p(λ)\n",
      "λ(t)\n",
      "Cosine\n",
      "sech (λ/2) /2π\n",
      "2 log cot\n",
      "\u0000 πt\n",
      "2\n",
      "\u0001\n",
      "Laplace\n",
      "e−|λ−µ|\n",
      "b\n",
      "/2b\n",
      "µ −bsgn(0.5 −t) log(1 −2|t −0.5|)\n",
      "Cauchy\n",
      "1\n",
      "π\n",
      "γ\n",
      "(λ−µ)2+γ2\n",
      "µ + γ tan\n",
      "\u0000 π\n",
      "2 (1 −2t)\n",
      "\u0001\n",
      "Cosine Shifted\n",
      "1\n",
      "2πsech\n",
      "\u0010\n",
      "λ−µ\n",
      "2\n",
      "\u0011\n",
      "µ + 2 log\n",
      "\u0000cot\n",
      "\u0000 πt\n",
      "2\n",
      "\u0001\u0001\n",
      "Cosine Scaled\n",
      "s\n",
      "2πsech\n",
      "\u0000 sλ\n",
      "2\n",
      "\u0001\n",
      "2\n",
      "s log\n",
      "\u0000cot\n",
      "\u0000 πt\n",
      "2\n",
      "\u0001\u0001\n",
      "Table 1: Overview of various Noise Schedules. The table categorizes them into five distinct types:\n",
      "Cosine, Laplace, Cauchy, and two variations of Cosine schedules. The second column p(λ) denotes\n",
      "the sampling probability at different noise intensities λ. The last column λ(t) indicates how to\n",
      "sample noise intensities for training. We derived their relationship in Equation 4 and Equation 6.\n",
      "indicate the noise intensities. In the Variance Preserving (VP) setting, the coefficients in Equation 1\n",
      "can be calculated by α2\n",
      "t =\n",
      "exp(λ)\n",
      "exp(λ)+1, σ2\n",
      "t =\n",
      "1\n",
      "exp(λ)+1.\n",
      "2.2\n",
      "IMPROVED NOISE SCHEDULE DESIGN\n",
      "Given that the timestep t is a random variable sampled from uniform distribution, the noise schedule\n",
      "implicitly defines the distribution of importance sampling on various noise levels. The sampling\n",
      "probability of noise intensity λ is:\n",
      "p(λ) = p(t)\n",
      "\f\n",
      "\f\n",
      "\f\n",
      "\f\n",
      "dt\n",
      "dλ\n",
      "\f\n",
      "\f\n",
      "\f\n",
      "\f .\n",
      "(3)\n",
      "Considering that t satisfies uniform distribution, and λ is monotonically decreasing with t, we have:\n",
      "p(λ) = −dt\n",
      "dλ.\n",
      "(4)\n",
      "We take cosine noise schedule (Nichol & Dhariwal, 2021) as an example, where αt = cos\n",
      "\u0000 πt\n",
      "2\n",
      "\u0001\n",
      ",\n",
      "σt = sin\n",
      "\u0000 πt\n",
      "2\n",
      "\u0001\n",
      ". Then we can deduce that λ = −2 log tan(πt/2) and t = 2/π arctan e−λ/2. Thus\n",
      "the distribution of λ is: p(λ) = −dt/dλ = sech(λ/2)/2π. This derivation illustrates the process of\n",
      "obtaining p(λ) from a noise schedule λ(t). On the other hand, we can derive the noise schedule from\n",
      "the sampling probability of different noise intensities p(λ). By integrating Equation 4, we have:\n",
      "t = 1 −\n",
      "Z λ\n",
      "−∞\n",
      "p(λ)dλ = P(λ),\n",
      "(5)\n",
      "λ = P−1(t),\n",
      "(6)\n",
      "where P(λ) represents the cumulative distribution function of λ. Thus we can obtain the noise\n",
      "schedule λ by applying the inverse function P−1. In conclusion, during the training process, the\n",
      "importance sampling of varying noise intensities essentially equates to the modification of the noise\n",
      "schedules.\n",
      "2.3\n",
      "UNIFIED FORMULATION FOR DIFFUSION TRAINING\n",
      "VDM++ (Kingma & Gao, 2023) proposes a unified formulation that encompasses recent prominent\n",
      "frameworks and loss weighting strategies for training diffusion models, as detailed below:\n",
      "Lw(θ) = 1\n",
      "2Ex∼D,ϵ∼N (0,I),λ∼p(λ)\n",
      "\u0014w(λ)\n",
      "p(λ) ∥ˆ\n",
      "ϵθ(xλ; λ) −ϵ∥2\n",
      "2\n",
      "\u0015\n",
      ",\n",
      "(7)\n",
      "where D signifies the training dataset, noise ϵ is drawn from a standard Gaussian distribution, and\n",
      "p(λ) is the distribution of noise intensities. Different predicting targets, such as x0 and v, can also\n",
      "be re-parameterized to ϵ-prediction. w(λ) denotes the loss weighting strategy. Although adjusting\n",
      "w(λ) is theoretically equivalent to altering p(λ). In practical training, directly modifying p(λ) to\n",
      "concentrate computational resources on training specific noise levels is more effective than enlarging\n",
      "the loss weight on specific noise levels. Therefore, we focus on how to design p(λ).\n",
      "3\n",
      "Technical Report\n",
      "Method\n",
      "w(λ)\n",
      "p(λ)\n",
      "Cosine\n",
      "e−λ/2\n",
      "sech(λ/2)\n",
      "Min-SNR\n",
      "e−λ/2 · min{1, γe−λ}\n",
      "sech(λ/2)\n",
      "Soft-Min-SNR\n",
      "e−λ/2 · γ/(eλ + γ)\n",
      "sech(λ/2)\n",
      "FM-OT\n",
      "(1 + e−λ)sech2(λ/4)\n",
      "sech2(λ/4)/8\n",
      "EDM\n",
      "(1 + e−λ)(0.52 + e−λ)N(λ; 2.4, 2.42)\n",
      "(0.52 + e−λ)N(λ; 2.4, 2.42)\n",
      "Table 2: Comparison of different methods and related loss weighting strategies. The w(λ) is intro-\n",
      "duced in Equation 7.\n",
      "2.4\n",
      "PRACTICAL SETTINGS\n",
      "Stable Diffusion 3 (Esser et al., 2024), EDM (Karras et al., 2022), and Min-SNR (Hang et al., 2023;\n",
      "Crowson et al., 2024) find that the denoising tasks with medium noise intensity is most critical to\n",
      "the overall performance of diffusion models. Therefore, we increase the probability of p(λ) when λ\n",
      "is of moderate size, and obtain a new noise schedule according to Section 2.2.\n",
      "Specifically, we investigate four novel noise strategies, named Cosine Shifted, Cosine Scaled,\n",
      "Cauchy, and Laplace respectively. The detailed setting are listed in Table 1. Cosine Shifted use\n",
      "the hyperparameter µ to explore where the maximum probability should be used. Cosine Scaled\n",
      "explores how much the noise probability should be increased under the use of Cosine strategy to\n",
      "achieve better results. The Cauchy distribution, provides another form of function that can adjust\n",
      "both amplitude and offset simultaneously. The Laplace distribution is characterized by its mean µ\n",
      "and scale b, controls both the magnitude of the probability and the degree of concentration of the\n",
      "distribution. These strategies contain several hyperparameters, which we will explore in Section 3.5.\n",
      "Unless otherwise stated, we report the best hyperparameter results.\n",
      "By re-allocating the computation resources at different noise intensities, we can train the complete\n",
      "denoising process. During sampling process, we standardize the sampled SNR to align with the\n",
      "cosine schedule, thereby focusing our exploration solely on the impact of different strategies during\n",
      "training. It is important to note that, from the perspective of the noise schedule, how to allocate the\n",
      "computation resource during inference is also worth reconsideration. We will not explore it in this\n",
      "paper and leave this as future work.\n",
      "3\n",
      "EXPERIMENTS\n",
      "3.1\n",
      "IMPLEMENTATION DETAILS\n",
      "Dataset. We conduct experiments on ImageNet (Deng et al., 2009) with 256 × 256 and 512 × 512\n",
      "resolution. For each image, we follow the preprocessing in Rombach et al. (2022) to center crop and\n",
      "encode images to latents. The shape of compressed latent feature is 32 × 32 × 4 for 2562 images\n",
      "and 64 × 64 × 4 for 5122 images.\n",
      "Network Architecture. We adopt DiT-B from Peebles & Xie (2023) as our backbone. We replace\n",
      "the last AdaLN Linear layer with vanilla linear. Others are kept the same as the original implemen-\n",
      "tation.\n",
      "Training Settings. We adopt the Adam optimizer with learning rate 1×10−4. We set the batch size\n",
      "to 256 as Peebles & Xie (2023); Hang et al. (2023). Each model is trained for 500K iterations if not\n",
      "specified. Our implementation is mainly built on OpenDiT (Zhao et al., 2024) and experiments are\n",
      "mainly conducted on 8×16G V100 GPUs.\n",
      "Baselines and Metrics. We compare our proposed noise schedule with several baseline settings\n",
      "in Table 2. For each setting, we sample images using DDIM (Song et al., 2021) with 50 steps.\n",
      "Despite the noise strategy for different settings may be different, we ensure they are the same at each\n",
      "sampling step. This approach is adopted to exclusively investigate the impact of the noise strategy\n",
      "during the training phase. Moreover, we report results with different classifier-free guidance scales,\n",
      "and the FID is calculated using 10K generated images.\n",
      "4\n",
      "Technical Report\n",
      "3.2\n",
      "COMPARISON WITH BASELINES AND LOSS WEIGHT DESIGNS\n",
      "This section details the principal findings from our experiments on the ImageNet-256 dataset, focus-\n",
      "ing on the comparative effectiveness of various noise schedules and loss weightings in the context\n",
      "of CFG values. Table 3 illustrates these comparisons, showcasing the performance of each method\n",
      "in terms of the FID-10K score.\n",
      "The experiments reveal that our proposed noise schedules, particularly Laplace, achieve the most\n",
      "notable improvements over the traditional cosine schedule, as indicated by the bolded best scores\n",
      "and the blue numbers representing the reductions compared to baseline’s best score of 10.85.\n",
      "We also provide a comparison with methods that adjust the loss weight, including Min-SNR and\n",
      "Soft-Min-SNR. We find that although these methods can achieve better results than the baseline,\n",
      "they are still not as effective as our method of modifying the noise schedule. This indicates that\n",
      "deciding where to allocate more computational resources is more efficient than adjusting the loss\n",
      "weight. Compared with other noise schedules like EDM (Karras et al., 2022) and Flow (Lipman\n",
      "et al., 2022), we found that no matter which CFG value, our results significantly surpass theirs under\n",
      "the same training iterations.\n",
      "Method\n",
      "CFG=1.5\n",
      "CFG=2.0\n",
      "CFG=3.0\n",
      "Cosine (Nichol & Dhariwal, 2021)\n",
      "17.79\n",
      "10.85\n",
      "11.06\n",
      "EDM (Karras et al., 2022)\n",
      "26.11\n",
      "15.09\n",
      "11.56\n",
      "FM-OT (Lipman et al., 2022)\n",
      "24.49\n",
      "14.66\n",
      "11.98\n",
      "Min-SNR (Hang et al., 2023)\n",
      "16.06\n",
      "9.70\n",
      "10.43\n",
      "Soft-Min-SNR (Crowson et al., 2024)\n",
      "14.89\n",
      "9.07\n",
      "10.66\n",
      "Cosine Shifted (Hoogeboom et al., 2023)\n",
      "19.34\n",
      "11.67\n",
      "11.13\n",
      "Cosine Scaled\n",
      "12.74\n",
      "8.04\n",
      "11.02\n",
      "Cauchy\n",
      "12.91\n",
      "8.14\n",
      "11.02\n",
      "Laplace\n",
      "16.69\n",
      "9.04\n",
      "7.96 (-2.89)\n",
      "Table 3: Comparison of various noise schedules and loss weightings on ImageNet-256, showing\n",
      "the performance (in terms of FID-10K) of different methods under different CFG values. The best\n",
      "results highlighted in bold and the blue numbers represent the improvement when compared with\n",
      "the baseline FID 10.85. The line in gray is our suggested noise schedule.\n",
      "Furthermore, we investigate the convergence speed of these method, and the results are shown in\n",
      "Figure 2. It can be seen that adjusting the noise schedule converges faster than adjusting the loss\n",
      "weight. Additionally, we also notice that the optimal training method may vary when using different\n",
      "CFG values for inference, but adjusting the noise schedule generally yields better results.\n",
      "3.3\n",
      "ROBUSTNESS ON DIFFERENT PREDICTING TARGETS\n",
      "We evaluate the effectiveness of our designed noise schedule across three commonly adopted pre-\n",
      "diction targets: ϵ, x0 and v. The results are shown in Table 4.\n",
      "We observed that regardless of the prediction target, our proposed Laplace strategy significantly out-\n",
      "performs the Cosine strategy. It’s noteworthy that as the Laplace strategy focuses the computation\n",
      "on medium noise levels during training, the extensive noise levels are less trained, which could po-\n",
      "tentially affect the overall performance. Therefore, we have slightly modified the inference strategy\n",
      "of DDIM to start sampling from tmax = 0.99.\n",
      "3.4\n",
      "ROBUSTNESS ON HIGH RESOLUTION IMAGES\n",
      "To explore the robustness of the adjusted noise schedule to different resolutions, we also designed\n",
      "experiments on Imagenet-512. As pointed out by Chen (2023), the adding noise strategy will cause\n",
      "more severe signal leakage as the resolution increases. Therefore, we need to adjust the hyperpa-\n",
      "rameters of the noise schedule according to the resolution.\n",
      "5\n",
      "Technical Report\n",
      "100K\n",
      "200K\n",
      "300K\n",
      "400K\n",
      "500K\n",
      "Training Iterations\n",
      "7.5\n",
      "10.0\n",
      "12.5\n",
      "15.0\n",
      "17.5\n",
      "20.0\n",
      "22.5\n",
      "25.0\n",
      "FID-10k\n",
      "11.06\n",
      "7.96\n",
      "Cosine (CFG=3,0)\n",
      "Min-SNR (CFG=3,0)\n",
      "Soft-Min-SNR (CFG=3,0)\n",
      "Laplace-(0, 0.5) (CFG=3,0)\n",
      "Figure 2: Comparison between adjusting the noise schedule, adjusting the loss weights and baseline\n",
      "setting. The Laplace noise schedule yields the best results and the fastest convergence speed.\n",
      "Predict Target\n",
      "Noise Schedule\n",
      "100K\n",
      "200k\n",
      "300k\n",
      "400k\n",
      "500k\n",
      "x0\n",
      "Cosine\n",
      "35.20\n",
      "17.60\n",
      "13.37\n",
      "11.84\n",
      "11.16\n",
      "Laplace (Ours)\n",
      "21.78\n",
      "10.86\n",
      "9.44\n",
      "8.73\n",
      "8.48\n",
      "v\n",
      "Cosine\n",
      "25.70\n",
      "14.01\n",
      "11.78\n",
      "11.26\n",
      "11.06\n",
      "Laplace (Ours)\n",
      "18.03\n",
      "9.37\n",
      "8.31\n",
      "8.07\n",
      "7.96\n",
      "ϵ\n",
      "Cosine\n",
      "28.63\n",
      "15.80\n",
      "12.49\n",
      "11.14\n",
      "10.46\n",
      "Laplace (Ours)\n",
      "27.98\n",
      "13.92\n",
      "11.01\n",
      "10.00\n",
      "9.53\n",
      "Table 4: Effectiveness evaluated using FID-10K score on different predicting targets. The proposed\n",
      "Laplace schedule performs better than the baseline Cosine schedule along with training iterations.\n",
      "Specifically, the baseline Cosine schedule achieves the best performance when the CFG value equals\n",
      "to 3. So we choose this CFG value for inference. Through systematic experimentation, we explored\n",
      "the appropriate values for the Laplace schedule’s parameter b, testing within the range {0.5, 0.75,\n",
      "1.0}, and determined that b = 0.75 was the most effective, resulting in an FID score of 9.09. This\n",
      "indicates that despite the need for hyperparameter tuning, adjusting the noise schedule can still stably\n",
      "bring performance improvements.\n",
      "Noise Schedule\n",
      "Cosine\n",
      "Laplace\n",
      "FID-10K\n",
      "11.91\n",
      "9.09 (-2.82)\n",
      "Table 5: FID-10K results on ImageNet-512. All models are trained for 500K iterations.\n",
      "3.5\n",
      "ABLATION STUDY\n",
      "We conduct an ablation study to analyze the impact of hyperparameters on various distributions of\n",
      "p(λ), which are enumerated below.\n",
      "Laplace distribution is easy to implement and we adjust the scale to make the peak at the\n",
      "middle timestep.\n",
      "We conduct experiments with different Laplace distribution scales b\n",
      "∈\n",
      "{0.25, 0.5, 1.0, 2.0, 3.0}. The results are shown in Figure 3. The baseline with standard cosine\n",
      "schedule achieves FID score of 17.79 with CFG=1.5, 10.85 with CFG=2.0, and 11.06 with CFG=3.0\n",
      "6\n",
      "Technical Report\n",
      "0.5\n",
      "1.0\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "3.0\n",
      "b\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "FID-10k\n",
      "12.93\n",
      "8.19\n",
      "7.96\n",
      "17.79\n",
      "10.85\n",
      "11.06\n",
      "Laplace, CFG=1.5\n",
      "Laplace, CFG=2.0\n",
      "Laplace, CFG=3.0\n",
      "Baseline, CFG=1.5\n",
      "Baseline, CFG=2.0\n",
      "Baseline, CFG=3.0\n",
      "Figure 3:\n",
      "FID-10K results on ImageNet-256 with different Laplace distribution scales b in\n",
      "{0.25, 0.5, 1.0, 2.0, 3.0}. The location parameter µ is fixed to 0. Baseline denotes standard co-\n",
      "sine schedule.\n",
      "after 500K iterations. We can see that the model with Laplace distribution scale b = 0.5 achieves\n",
      "the best performance 7.96 with CFG=3.0, which is relatively 26.6% better than the baseline.\n",
      "Cauchy distribution is another heavy-tailed distribution that can be used for noise schedule design.\n",
      "The distribution is not symmetric when the location parameter is not 0. We conduct experiments\n",
      "with different Cauchy distribution parameters and the results are shown in Table 6. Cauchy(0, 0.5)\n",
      "means 1\n",
      "π\n",
      "γ\n",
      "(λ−µ)2+γ2 with µ = 0, γ = 0.5. We can see that the model with µ = 0 achieve better\n",
      "performance than the other two settings when fixing γ to 1. It means that the model with more\n",
      "probability mass around λ = 0 performs better than others biased to negative or positive directions.\n",
      "Cauchy(0, 0.5)\n",
      "Cauchy(0, 1)\n",
      "Cauchy(-1, 1)\n",
      "Cauchy(1, 1)\n",
      "CFG=1.5\n",
      "12.91\n",
      "14.32\n",
      "18.12\n",
      "16.60\n",
      "CFG=2.0\n",
      "8.14\n",
      "8.93\n",
      "10.38\n",
      "10.19\n",
      "CFG=3.0\n",
      "11.02\n",
      "11.26\n",
      "10.81\n",
      "10.94\n",
      "Table 6: FID-10k results on ImageNet-256 with different Cauchy distribution parameters.\n",
      "Cosine Shifted (Hoogeboom et al., 2023) is the shifted version of the standard cosine schedule.\n",
      "We evaluate the schedules with both positive and negative µ values. Shifted with µ = 1 achieves\n",
      "FID-10k score {19.34, 11.67, 11.13} with CFG {1.5, 2.0, 3.0}. Results with shifted value µ = −1\n",
      "are {19.30, 11.48, 11.28}. Comparatively, both scenarios demonstrate inferior performance relative\n",
      "to the baseline cosine schedule (µ = 0). Additionally, by examining the data presented in Table 6,\n",
      "we find concentrated on λ = 0 can best improve the results.\n",
      "Cosine Scaled is also a modification of Cosine schedule. When s is equal to 1, it becomes the\n",
      "standard Cosine version. s > 1 means sampling more heavily around λ = 0 while s < 1 means\n",
      "sampling more uniformly of all λ. We report related results in Table 7. Larger values of s(s > 1)\n",
      "outperform the baseline; however, s should not be excessively large and must remain within a valid\n",
      "range. A model trained with s = 2 attains a score of 8.04, representing a 25.9% improvement over\n",
      "the baseline.\n",
      "7\n",
      "Technical Report\n",
      "1/s\n",
      "1.3\n",
      "1.1\n",
      "0.5\n",
      "0.25\n",
      "CFG=1.5\n",
      "39.74\n",
      "22.60\n",
      "12.74\n",
      "15.83\n",
      "CFG=2.0\n",
      "23.38\n",
      "12.98\n",
      "8.04\n",
      "8.64\n",
      "CFG=3.0\n",
      "13.94\n",
      "11.16\n",
      "11.02\n",
      "8.26\n",
      "Table 7: FID-10k results on ImageNet-256 with different scales of Cosine Scaled distribution.\n",
      "4\n",
      "RELATED WORK\n",
      "EFFICIENT DIFFUSION TRAINING\n",
      "Generally speaking, the diffusion model uses a network with shared parameters to denoise different\n",
      "noise intensities. However, the different noise levels may introduce conflicts during training, which\n",
      "makes the convergence slow. Min-SNR (Hang et al., 2023) seeks the Pareto optimal direction for\n",
      "different tasks, achieves better convergence on different predicting targets. HDiT (Crowson et al.,\n",
      "2024) propose a soft version of Min-SNR to further improve the efficiency on high resolution image\n",
      "synthesis. Stable Diffusion 3 (Esser et al., 2024) puts more weight on the middle timesteps by\n",
      "multiplying the distribution of logit normal distribution. On the other hand, architecture modification\n",
      "is also explored to improve diffusion training. DiT (Peebles & Xie, 2023) proposes adaptive Layer\n",
      "Normalization with zero initialization to improve the training of Transformer architectures. A more\n",
      "robust ADM UNet with better training dynamics is proposed in EDM2 (Karras et al., 2024) by\n",
      "preserving activation, weight, and update magnitudes.\n",
      "NOISE SCHEDULE DESIGN FOR DIFFUSION MODELS\n",
      "The design of the noise schedule plays a critical role in training diffusion models. In DDPM, Ho et al.\n",
      "(2020) propose linear schedule for the noise level, which is later used in Stable Diffusion (Rombach\n",
      "et al., 2022) version 1.5 and 2.0. iDDPM (Nichol & Dhariwal, 2021) introduces a cosine schedule\n",
      "aimed at bringing the sample with the highest noise level closer to pure Gaussian noise. EDM (Kar-\n",
      "ras et al., 2022) proposes a new continuous framework and make the logarithm of noise intensity\n",
      "sampled from a Gaussian distribution. Flow matching with optimal transport (Lipman et al., 2022;\n",
      "Liu et al., 2022) linearly interpolates the noise and data point as the input of flow-based models.\n",
      "Chen (2023) underscored the need for adapting the noise schedule according to the token length,\n",
      "and several other works (Lin et al., 2024; Tang et al., 2023) emphasize that it’s important to prevent\n",
      "signal leakage in the final step.\n",
      "5\n",
      "CONCLUSION\n",
      "In this technical report, we present a novel method for enhancing diffusion model training by re-\n",
      "defining the noise schedule. We theoretically analyzed that this approach equates to performing\n",
      "importance sampling on the noise. Empirical results show that our proposed Laplace noise sched-\n",
      "ule, focusing computational resources on mid-range steps, yields superior performance compared to\n",
      "the adjustment of loss weights under constrained budgets. This study not only contributes signifi-\n",
      "cantly to developing efficient training techniques for diffusion models but also offers potential for\n",
      "future large-scale applications.\n",
      "REFERENCES\n",
      "Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika\n",
      "Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and Ming-Yu Liu. ediff-i: Text-\n",
      "to-image diffusion models with ensemble of expert denoisers. arXiv preprint arXiv:2211.01324,\n",
      "2022.\n",
      "Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu. All are worth\n",
      "words: A vit backbone for diffusion models. arXiv preprint arXiv:2209.12152, 2022.\n",
      "8\n",
      "Technical Report\n",
      "Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe\n",
      "Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh.\n",
      "Video\n",
      "generation models as world simulators. 2024. URL https://openai.com/research/\n",
      "video-generation-models-as-world-simulators.\n",
      "Ting Chen.\n",
      "On the importance of noise scheduling for diffusion models.\n",
      "arXiv preprint\n",
      "arXiv:2301.10972, 2023.\n",
      "Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, and Sungroh Yoon.\n",
      "Perception prioritized training of diffusion models. In Proceedings of the IEEE/CVF Conference\n",
      "on Computer Vision and Pattern Recognition, pp. 11472–11481, 2022.\n",
      "Katherine Crowson, Stefan Andreas Baumann, Alex Birch, Tanishq Mathew Abraham, Daniel Z\n",
      "Kaplan, and Enrico Shippole. Scalable high-resolution pixel-space image synthesis with hourglass\n",
      "diffusion transformers. In Forty-first International Conference on Machine Learning, 2024.\n",
      "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hi-\n",
      "erarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,\n",
      "pp. 248–255. Ieee, 2009.\n",
      "Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances\n",
      "in Neural Information Processing Systems, 34:8780–8794, 2021.\n",
      "Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M¨\n",
      "uller, Harry Saini, Yam\n",
      "Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for\n",
      "high-resolution image synthesis. arXiv preprint arXiv:2403.03206, 2024.\n",
      "Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, and\n",
      "Baining Guo. Vector quantized diffusion model for text-to-image synthesis. In Proceedings of\n",
      "the IEEE/CVF conference on computer vision and pattern recognition, pp. 10696–10706, 2022.\n",
      "Tiankai Hang, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin Geng, and Baining\n",
      "Guo. Efficient diffusion training via min-snr weighting strategy. In Proceedings of the IEEE/CVF\n",
      "International Conference on Computer Vision (ICCV), pp. 7441–7451, October 2023.\n",
      "Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in\n",
      "Neural Information Processing Systems, 33:6840–6851, 2020.\n",
      "Emiel Hoogeboom, Jonathan Heek, and Tim Salimans. simple diffusion: End-to-end diffusion for\n",
      "high resolution images. In International Conference on Machine Learning, pp. 13213–13232.\n",
      "PMLR, 2023.\n",
      "Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.\n",
      "Elucidating the design space of\n",
      "diffusion-based generative models.\n",
      "In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and\n",
      "Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.\n",
      "URL\n",
      "https://openreview.net/forum?id=k7FuTOWMOc7.\n",
      "Tero Karras, Miika Aittala, Jaakko Lehtinen, Janne Hellsten, Timo Aila, and Samuli Laine. Analyz-\n",
      "ing and improving the training dynamics of diffusion models. In Proc. CVPR, 2024.\n",
      "Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. Ad-\n",
      "vances in neural information processing systems, 34:21696–21707, 2021.\n",
      "Diederik P Kingma and Ruiqi Gao. Understanding diffusion objectives as the ELBO with simple\n",
      "data augmentation. In Thirty-seventh Conference on Neural Information Processing Systems,\n",
      "2023. URL https://openreview.net/forum?id=NnMEadcdyD.\n",
      "Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Common diffusion noise schedules and\n",
      "sample steps are flawed. In Proceedings of the IEEE/CVF winter conference on applications of\n",
      "computer vision, pp. 5404–5411, 2024.\n",
      "Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow match-\n",
      "ing for generative modeling. In The Eleventh International Conference on Learning Representa-\n",
      "tions, 2022.\n",
      "9\n",
      "Technical Report\n",
      "Xingchao Liu, Chengyue Gong, et al. Flow straight and fast: Learning to generate and transfer data\n",
      "with rectified flow. In The Eleventh International Conference on Learning Representations, 2022.\n",
      "Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models.\n",
      "In International Conference on Machine Learning, pp. 8162–8171. PMLR, 2021.\n",
      "William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of\n",
      "the IEEE/CVF International Conference on Computer Vision, pp. 4195–4205, 2023.\n",
      "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-\n",
      "conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.\n",
      "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨\n",
      "orn Ommer. High-\n",
      "resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Con-\n",
      "ference on Computer Vision and Pattern Recognition, pp. 10684–10695, 2022.\n",
      "Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kam-\n",
      "yar Seyed Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan\n",
      "Ho, David J. Fleet, and Mohammad Norouzi.\n",
      "Photorealistic text-to-image diffusion mod-\n",
      "els with deep language understanding.\n",
      "In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\n",
      "and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL\n",
      "https://openreview.net/forum?id=08Yk-n5l2Al.\n",
      "Tim Salimans and Jonathan Ho. Progressive distillation for fast sampling of diffusion models. In\n",
      "International Conference on Learning Representations, 2022. URL https://openreview.\n",
      "net/forum?id=TIdIXIpzhoI.\n",
      "Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In Interna-\n",
      "tional Conference on Learning Representations, 2021.\n",
      "Zhicong Tang, Shuyang Gu, Chunyu Wang, Ting Zhang, Jianmin Bao, Dong Chen, and Baining\n",
      "Guo. Volumediffusion: Flexible text-to-3d generation with efficient volumetric encoder. arXiv\n",
      "preprint arXiv:2312.11459, 2023.\n",
      "S. Yang, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole. Score-based genera-\n",
      "tive modeling through stochastic differential equations. In International Conference on Learning\n",
      "Representations, 2021.\n",
      "Xuanlei Zhao, Zhongkai Zhao, Ziming Liu, Haotian Zhou, Qianli Ma, and Yang You. Opendit:\n",
      "An easy, fast and memory-efficient system for dit training and inference. https://github.\n",
      "com/NUS-HPC-AI-Lab/OpenDiT, 2024.\n",
      "10\n",
      "Technical Report\n",
      "APPENDIX A: DETAILED IMPLEMENTATION FOR NOISE SCHEDULE\n",
      "We provide a simple PyTorch implementation for the Laplace noise schedule and its application in\n",
      "training. This example can be adapted to other noise schedules, such as the Cauchy distribution,\n",
      "by replacing the laplace noise schedule function. The model accepts noisy samples xt,\n",
      "timestep t, and an optional condition tensor c as inputs. This implementation supports prediction of\n",
      "{x0, v, ϵ}.\n",
      "1\n",
      "import torch\n",
      "2\n",
      "3\n",
      "4\n",
      "def laplace_noise_schedule(mu=0.0, b=0.5):\n",
      "5\n",
      "# refer to Table 1\n",
      "6\n",
      "lmb = lambda t: mu - b * torch.sign(0.5 - t) * \\\n",
      "7\n",
      "torch.log(1 - 2 * torch.abs(0.5 - t))\n",
      "8\n",
      "snr_func\n",
      "= lambda t: torch.exp(lmb(t))\n",
      "9\n",
      "alpha_func = lambda t: torch.sqrt(snr_func(t) / (1 + snr_func(t)))\n",
      "10\n",
      "sigma_func = lambda t: torch.sqrt(1 / (1 + snr_func(t)))\n",
      "11\n",
      "12\n",
      "return alpha_func, sigma_func\n",
      "13\n",
      "14\n",
      "15\n",
      "def training_losses(model, x, timestep, condition, noise=None,\n",
      "16\n",
      "predict_target=\"v\", mu=0.0, b=0.5):\n",
      "17\n",
      "18\n",
      "if noise is None:\n",
      "19\n",
      "noise = torch.randn_like(x)\n",
      "20\n",
      "21\n",
      "alpha_func, sigma_func = laplace_noise_schedule(mu, b)\n",
      "22\n",
      "alphas = alpha_func(timestep)\n",
      "23\n",
      "sigmas = sigma_func(timestep)\n",
      "24\n",
      "25\n",
      "# add noise to sample\n",
      "26\n",
      "x_t = alphas.view(-1, 1, 1, 1) * x + sigmas.view(-1, 1, 1, 1) * noise\n",
      "27\n",
      "# velocity\n",
      "28\n",
      "v_t = alphas.view(-1, 1, 1, 1) * noise - sigmas.view(-1, 1, 1, 1) * x\n",
      "29\n",
      "30\n",
      "model_output = model(x_t, timestep, condition)\n",
      "31\n",
      "if predict_target == \"v\":\n",
      "32\n",
      "loss = (v_t - model_output) ** 2\n",
      "33\n",
      "elif predict_target == \"x0\":\n",
      "34\n",
      "loss = (x - model_output) ** 2\n",
      "35\n",
      "else: # predict_target == \"noise\":\n",
      "36\n",
      "loss = (noise - model_output) ** 2\n",
      "37\n",
      "38\n",
      "return loss.mean()\n",
      "APPENDIX B: DETAILS FOR SAMPLING PROCESS\n",
      "As we mentioned before, choosing which noise schedule for sampling worth exploration. In this\n",
      "paper, we focus on exploring what kind of noise schedule is needed for training. Therefore, we\n",
      "adopted the same inference strategy as the cosine schedule to ensure a fair comparison. Specifically,\n",
      "first we sample {t0, t1, . . . , ts} from uniform distribution U[0, 1], then get the corresponding SNRs\n",
      "from Cosine schedule: {\n",
      "α2\n",
      "t0\n",
      "σ2\n",
      "t0 ,\n",
      "α2\n",
      "t1\n",
      "σ2\n",
      "t1 , . . . ,\n",
      "α2\n",
      "ts\n",
      "σ2\n",
      "ts }. According to Equation 6, we get the corresponding\n",
      "{t′\n",
      "0, t′\n",
      "1, . . . , t′\n",
      "s} by inverting these SNR values through the respective noise schedules. Finally, we\n",
      "use DDIM (Song et al., 2021) to sample with these new calculated {t′}.\n",
      "11\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "publication date of Biomechanics-informed Non-rigid Medical Image Registration and its Inverse Material Property Estimation with Linear and Nonlinear Elasticity: Thu, 4 Jul 2024 (continued, showing 3 of 115 entries )\n",
      "Title: Biomechanics-informed Non-rigid Medical Image Registration and its Inverse Material Property Estimation with Linear and Nonlinear Elasticity\n",
      "Authors of Biomechanics-informed Non-rigid Medical Image Registration and its Inverse Material Property Estimation with Linear and Nonlinear Elasticity: Zhe Min, Zachary M.C. Baum, Shaheer U. Saeed, Mark Emberton, Dean C. Barratt, Zeike A. Taylor, Yipeng Hu\n",
      "\n",
      "Biomechanics-informed Non-rigid Medical Image\n",
      "Registration and its Inverse Material Property\n",
      "Estimation with Linear and Nonlinear Elasticity\n",
      "Zhe Min1,2(\u0000), Zachary M. C. Baum2, Shaheer U. Saeed2, Mark Emberton3,\n",
      "Dean C. Barratt2, Zeike A. Taylor4, and Yipeng Hu2\n",
      "1 School of Control Science and Engineering, Shandong University, Jinan, China\n",
      "minzhe@sdu.edu.cn;z.min@ucl.ac.uk\n",
      "2 Centre for Medical Image Computing and Wellcome/EPSRC Centre for\n",
      "Interventional & Surgical Sciences, University College London, London, UK\n",
      "3 Division of Surgery & Interventional Science, University College London, London,\n",
      "UK\n",
      "4 CISTIB Centre for Computational Imaging and Simulation Technologies in\n",
      "Biomedicine, Institute of Medical and Biological Engineering, University of Leeds,\n",
      "Leeds, UK\n",
      "Abstract. This paper investigates both biomechanical-constrained non-\n",
      "rigid medical image registrations and accurate identifications of mate-\n",
      "rial properties for soft tissues, using physics-informed neural networks\n",
      "(PINNs). The nonlinear elasticity theory is leveraged to formally estab-\n",
      "lish the partial differential equations (PDEs) representing physics laws\n",
      "of biomechanical constraints to be satisfied, with which registration and\n",
      "identification tasks are treated as forward (i.e., data-driven solutions of\n",
      "PDEs) and inverse (i.e., parameter estimation) problems under PINNs\n",
      "respectively. While the forward problem has direct clinical applications in\n",
      "guiding targeted biopsy and treatment, the solution to the inverse prob-\n",
      "lem may open new research directions in quantifying disease-indicative\n",
      "mechanical properties of in vivo tissues. Two net configurations (i.e., Cfg1\n",
      "and Cfg2) have also been compared for both linear and nonlinear physics\n",
      "models, according to whether backbones are shared between branches or\n",
      "not. Two sets of experiments have been conducted, using pairs of un-\n",
      "deformed and deformed MR images from clinical cases of prostate can-\n",
      "cer biopsy. In the first experiment, against the finite-element-computed\n",
      "ground-truth, the root mean squared error (rmse) of registration for sur-\n",
      "face points was reduced from 1.83±0.51 mm without PINNs to 1.43±0.70\n",
      "mm (Cfg1, p = 0.024) and 1.23 ± 0.69 mm (Cfg2, p < 0.001) with lin-\n",
      "ear elasticity, and to 1.45 ± 0.84 mm (Cfg1, p = 0.004) and 1.24 ± 0.69\n",
      "mm (Cfg2, p < 0.001) with nonlinear elasticity, while average differences\n",
      "between linear and nonlinear models were not found statistically signif-\n",
      "icant (e.g., p = 0.972 between two Cfg1s) but their respective benefits\n",
      "may depend on specific patients. In the second experiment, the non-\n",
      "linear model exhibited evident advantages over the linear counterpart\n",
      "(p = 0.002) in predicting ratios of tissue stiffness (i.e., Young’s mod-\n",
      "ulus) between two subregions (i.e., peripheral and transition zones) of\n",
      "the prostate, with the mean average percentage error (mAPE) values\n",
      "arXiv:2407.03292v1  [cs.CV]  3 Jul 2024\n",
      "2\n",
      "Z. Min et al.\n",
      "being 14.20%±14.12% and 76.28%±30.97%, respectively. The codes are\n",
      "available at https://github.com/ZheMin-1992/Registration_PINNs.\n",
      "Keywords: Medical image registration · Biomechanical constraints ·\n",
      "Physics-informed neural networks · Material property estimation.\n",
      "1\n",
      "Introduction\n",
      "Biomechanical modelling plays an important role in regularising medical image\n",
      "registration [1,26,27] that further enables surgical guidance for different organs\n",
      "(e.g., prostate [1,7,24,28], liver [17], brain [10,11] and heart [19]), for example,\n",
      "to constrain predicted spatial transformations to be physically plausible, un-\n",
      "der either iterative optimisation [24] or neural-network-training [7,28] schemes.\n",
      "Biomechanical constraints could vary from simple linear [12] to complex non-\n",
      "linear models [1,15], while they require values of material properties if applied\n",
      "to the registration problem. This paper investigates both aspects by leveraging\n",
      "the capabilities of physics-informed neural networks (PINNs) to seek data-driven\n",
      "solutions (i.e., forward problem) and enable data-driven discovery (i.e., inverse\n",
      "problem) of partial differential equations (PDEs) [9] respectively, in the non-\n",
      "rigid medical image registration and material property estimation.\n",
      "Linear elasticity models assuming a linear relationship between stress and\n",
      "strain, are only effective for modelling small deformations under low-stress condi-\n",
      "tions [12]. Nonlinear elasticity models built on more complex constitutive models\n",
      "and strain energy functions, are better suited for capturing large deformations\n",
      "and nonlinear material behavior [12]. For example, the anisotropic viscoelasticity\n",
      "constitutive models [4,13,15] were utilised for simulating soft tissues’ deforma-\n",
      "tions, led to more realistic organ (e.g., liver) geometries than linear models with\n",
      "desired properties such as stress dissipation [23]. The nonlinear finite-element-\n",
      "analysis was developed for modelling-fidelity surgical simulations [22]. However,\n",
      "the choices of hyperviscoelastic, hyperelastic, and linear elastic constitutive mod-\n",
      "els were demonstrated to be not important in estimating brain shifts for an\n",
      "image-guided neurosurgery procedure [25]. It is unclear whether a more complex\n",
      "nonlinear model (i.e., both geometrical and constitutive models) could make a\n",
      "difference in the non-rigid point set registration problem.\n",
      "Material property estimation aims to quantify mechanical properties of ma-\n",
      "terials (e.g., soft tissues), which can be used to develop customized surgical\n",
      "plans that could improve surgical outcomes [5,6]. Perhaps more interestingly, it\n",
      "may assist disease detection and localisation, as studies frequently found in vitro\n",
      "tumour has distinct mechanical properties compared to the healthy tissue [8].\n",
      "The identifications of bulk and shear modulus, under both linear elasticity and\n",
      "hyperelasticity models, were explored using specimens with simple one-or-two\n",
      "layers structures through experimental tests (e.g., uniaxial tension or compres-\n",
      "sion) [3]. The authors revealed multiple findings about under what conditions\n",
      "parameters are identifiable, for example, to compute material parameters of a\n",
      "single-layered specimen, a uniaxial tensile test either together with lateral strain\n",
      "Title Suppressed Due to Excessive Length\n",
      "3\n",
      "measurement, with torsion or with a shear experiment is needed [3]. We note\n",
      "that circumstances are much more complicated in both soft-tissue deformation\n",
      "modelling where exact values of stress and strain are unknown, and image reg-\n",
      "istration where displacement vectors of voxels need to be estimated. It is thus\n",
      "unknown whether material properties are identifiable or not, within the chal-\n",
      "lenging scenario of image registration where boundary conditions also need to be\n",
      "estimated.\n",
      "To answer the first question of whether nonlinear elasticity models are bet-\n",
      "ter than linear counterparts in registration, in a similar fashion with a recent\n",
      "work [14] where linear elasticity was adopted, this study incorporates nonlinear\n",
      "biomechanical constraints in forms of PDEs into a PINN for registration. The\n",
      "findings first confirmed the validity of adopting PINNs to impose biomechanical\n",
      "constraints for predicted transformations and to reduce registration error, and\n",
      "also indicated that there existed no statistically significant difference between\n",
      "average performances using linear and nonlinear models while choices may de-\n",
      "pend on specific patients. To answer the second question of whether material\n",
      "properties are identifiable along with registration, PINNs were utilised to for-\n",
      "mulate the joint optimisation framework of the registration problem and the\n",
      "material property estimation problem. The results demonstrated that ratios of\n",
      "soft tissues’ stiffness (i.e., Young’s modulus) between two distinct compartments\n",
      "(i.e.,the peripheral zone and transition zone) of the prostate gland could be suc-\n",
      "cessfully recovered, while nonlinear models exhibited evident advantages over\n",
      "their linear counterparts in this problem.\n",
      "Our contributions are summarised as follows. 1) We developed a learning-\n",
      "based biomechanical-constrained non-rigid registration algorithm using PINNs,\n",
      "where linear elasticity is generalised to the nonlinear version. 2) We demon-\n",
      "strated extensively that nonlinear elasticity shows no statistical significance\n",
      "against linear models in computing point-wise displacement vectors but their\n",
      "respective benefits may depend on specific patients, with finite-element (FE)\n",
      "computed ground-truth. 3) We formulated and solved the inverse parameter\n",
      "estimation problem, under the joint optimisation scheme of registration and pa-\n",
      "rameter identification using PINNs, whose solutions can be accurately found by\n",
      "locating saddle points of the optimisation.\n",
      "2\n",
      "Methods\n",
      "The non-rigid 3D point set registration problem in fields of medical imaging,\n",
      "is to warp the source point set PS ∈RNs×3 with ps ∈R3 to the target point\n",
      "set PT ∈RNt×3 with pt ∈R3, so as to accurately map important anatomical\n",
      "structures in two spaces. The warped source point set is T(PS) = PS + DS,\n",
      "where the displacement vectors are DS ∈RNs×3 with ds ∈R3.\n",
      "The idea of imposing biomechanical constraints in the registration problem\n",
      "with physics-informed neural networks (PINNs), like that in [14], is to predict\n",
      "point-wise displacement vectors and biomechanical-related values (e.g., stress\n",
      "or strain), of which the underlying physics laws (i.e., governing equations) usu-\n",
      "4\n",
      "Z. Min et al.\n",
      "MLP(3)\n",
      "MLP\n",
      "(1024,512,256,128,64)\n",
      "Kinematic \n",
      "Equation\n",
      "PointNet\n",
      "PointNet\n",
      "Global Feature Extraction (GFE)\n",
      "add\n",
      "Chamfer Loss\n",
      "Point Transformation (PT)\n",
      "ℒ𝐶\n",
      "𝑘\n",
      "Deformed \n",
      "MRI\n",
      "𝑵𝑠× 3\n",
      "𝑁𝑠× 3\n",
      "1024\n",
      "1024\n",
      "2048\n",
      "𝑁𝑠× 2051\n",
      "𝑵𝒔× 𝟔\n",
      "MRI\n",
      "ℒ𝐸\n",
      "𝑘\n",
      "ℒ𝑆\n",
      "𝑘\n",
      "ℒ𝑅\n",
      "𝑘\n",
      "Constitutive Equation\n",
      "Elastic Energy Cost\n",
      "Static Equilibrium \n",
      " Equation\n",
      "Displacement Branch\n",
      "𝑵𝒔× 𝟔\n",
      "Stress Branch\n",
      "Configuration1: individual backbones \n",
      "(GFE) for two branches; \n",
      "Configuration2: one shared backbone\n",
      " (as shown here) for two branches.\n",
      "Governing equations within the physics-informed neural \n",
      "networks(PINNs):Linear elasticity versus Nonlinear elasticity.\n",
      "Fig. 1. The schematic of the proposed physics-informed neural networks.\n",
      "ally represented by partial differential equations (PDEs) should be satisfied. As\n",
      "shown in Fig. 1 and introduced in details in Sect. 2.3, there are three main govern-\n",
      "ing equations and one energy function in modelling deformation of soft tissues,\n",
      "from simple linear relationships [14], to the elaborate nonlinear cases (i.e., com-\n",
      "pressible Neo-Hookean model [16]) in this study. Let Dk be the data set of k-th\n",
      "patient, containing PS and PT , Fig. 1 shows the algorithm schematic where the\n",
      "displacement-predicting branch is gθg(Dk) and the stress-predicting branch is\n",
      "hθh(Dk) with learnable parameters θg and θh, which together constitutes eθ(Dk)\n",
      "with θ. Two net configurations have been compared, where individual and shared\n",
      "(as depicted in Fig. 1) backbones (i.e., global feature extraction module based\n",
      "on PointNet [18]) are utilised to extract features for two branches respectively.\n",
      "For clarity, the four models with two net configurations and two physics models\n",
      "are denoted as Linear Cfg1, Linear Cfg2, Nonlinear Cfg1 and Nonlinear Cfg2.\n",
      "2.1\n",
      "The Forward Problem of Non-Rigid Point Set Registration\n",
      "using PINNs\n",
      "The registration task is formulated as the forward problem (i.e., the data-driven\n",
      "solutions of PDEs) which estimates the unknown function gθg(Dk) within the\n",
      "PINNs framework where nonlinear PDEs are parameterised by lame parameters\n",
      "λs ∈R and µs ∈R at the point ps. Here, boundary conditions are ‘actual’ dis-\n",
      "placement vectors of source points which are unknown and thus their estimation\n",
      "errors are approximated with the Chamfer loss. The Chamfer loss Lk\n",
      "R(θg; Dk)\n",
      "first seeks the nearest point in the other point set (e.g., T(PS)) to each point in\n",
      "one point set(e.g., PT ) and computes the L2 distance, repeats the above opera-\n",
      "tion for the other point set T(PS) and returns the sum of average distances. The\n",
      "Chamfer loss can be either applied to all points PS and PT or surface points\n",
      "only Psurface\n",
      "S\n",
      "∈RN surface\n",
      "s\n",
      "×3 and Psurface\n",
      "T\n",
      "∈RN surface\n",
      "t\n",
      "×3 (i.e., ‘strict’ boundary con-\n",
      "ditions where surface points are points on the boundary). By regarding all points\n",
      "as ‘collocation’ points following PINNs notation conventions [20], as shown in\n",
      "Title Suppressed Due to Excessive Length\n",
      "5\n",
      "Fig. 1, nonlinear PDEs include the static equilibrium deviation loss Lk\n",
      "S(θh; Dk) =\n",
      "PNs\n",
      "s=1 fstatic( ∂σs\n",
      "∂x , ∂σs\n",
      "∂y , ∂σs\n",
      "∂z ) that regularizes spatial derivatives of stress σs, the\n",
      "constitutive deviation loss Lk\n",
      "C(θ; Dk) = PNs\n",
      "s=1 fconst(σs, ∂ds\n",
      "∂ps , λs, µs) that relates\n",
      "σs and spatial derivatives of displacements ∂ds\n",
      "∂ps with λs and µs, and the elastic\n",
      "energy loss Lk\n",
      "E(θh; Dk) = PNs\n",
      "s=1 fenergy(εs, λs, µs) that relies on strains and lame\n",
      "parameters. Note that fstatic(⋆), fconst(⋆) and fenergy(⋆) will be defined in Sect.\n",
      "2.3. The training loss Lk(θ; Dk) in the forward problem for the k-th subject is\n",
      "given by a (w ∈R+)-weighted sum of these terms,\n",
      "Lk(θ; Dk) = wLk\n",
      "R(θg; Dk) + Lk\n",
      "S(θh, Dk) + Lk\n",
      "C(θ; Dk) + Lk\n",
      "E(θh; Dk),\n",
      "(1)\n",
      "where Dk is considered to include lamé parameters λs and µs.\n",
      "2.2\n",
      "The Inverse Problem of Identifying Material Properties of Soft\n",
      "Tissues using PINNs\n",
      "In Sect. 2.1, we treat the registration as the forward problem using PINNs, which\n",
      "necessitates knowing material properties (e.g., Young’s modulus). In contrast,\n",
      "the parameter (e.g., material properties) estimation is regarded as the inverse\n",
      "problem (i.e., the data-driven discovery of PDEs) under a similar PINNs frame-\n",
      "work. Consider two distinct compartments of the prostate gland, i.e., the pe-\n",
      "ripheral zone (PZ) and transition zone (TZ), which exhibit different stiffness\n",
      "magnitudes [6,5]. Let DPZ\n",
      "k\n",
      "and DTZ\n",
      "k\n",
      "denote points in PZ and TZ, EPZ\n",
      "k\n",
      "∈R and\n",
      "ETZ\n",
      "k\n",
      "∈R be their respective Young’s modulus values. The particular example\n",
      "of the inverse problem here, assuming that ETZ\n",
      "k\n",
      "is known, is to estimate the\n",
      "ratio βk ∈R of EPZ\n",
      "k\n",
      "to ETZ\n",
      "k , which plays an important role in biomechanics-\n",
      "constrained non-rigid point set registration as verified in [6]. To this end, one\n",
      "learnable weight that functions as βk is added into the network eθ(Dk). The loss\n",
      "function for the inverse problem, under the joint learning scheme of point set\n",
      "registration and parameter estimation, is\n",
      "Lk(θ, βk; Dk) = wLk\n",
      "R(θg; Dk)+Lk\n",
      "S(θh, Dk)+Lk\n",
      "C(θ, βk; Dk)+Lk\n",
      "E(θh, βk; Dk), (2)\n",
      "where Lk\n",
      "C(θ, βk; Dk) and Lk\n",
      "E(θ, βk; Dk) can be expanded as Lk\n",
      "C/E(θ, βk; Dk) ≡\n",
      "Lk\n",
      "C/E(θ; DTZ\n",
      "k , ETZ\n",
      "k ) + Lk\n",
      "C/E(θ; DPZ\n",
      "k , βkETZ\n",
      "k ), where lame parameters λs and µs\n",
      "at ps are computed using ETZ\n",
      "k\n",
      "and βkETZ\n",
      "k\n",
      "depending on the sub-regions (i.e.,\n",
      "DPZ\n",
      "k\n",
      "or DTZ\n",
      "k ) in which ps falls.\n",
      "The optimisation problem minimising Lk(θ, βk; Dk) in Eq. (2) is likely to be\n",
      "ill-posed, in that it contains unknowns in both registration-related and physics-\n",
      "laws-related loss terms (i.e., PDEs). Instead of seeking local minimums w.r.t.\n",
      "material parameters which is likely to be unidentifiable and produces naive solu-\n",
      "tions, we investigate saddle points that are much more interesting and represent\n",
      "practically meaningful solutions as will be demonstrated in Sect. 3.\n",
      "6\n",
      "Z. Min et al.\n",
      "2.3\n",
      "Governing Equations for Deforming Soft Tissues Considering\n",
      "Nonlinear Elasticity\n",
      "In this section, we describe in details PDEs representing governing equations in\n",
      "both the forward problem in Sect. 2.1 and the inverse problem in Sect. 2.2.\n",
      "Nonlinear Strain-displacement Equations The nonlinear strain-displacement\n",
      "equation at a source point ps is\n",
      "εs = 1\n",
      "2(∇ds + ∇dT\n",
      "s + ∇dT\n",
      "s ∇ds),\n",
      "(3)\n",
      "where εs is the Green-Lagrangian strain tensor at ps, ∇ds is the displacement\n",
      "gradient w.r.t. spatial coordinates x, y, z of ps. As shown in Fig. 1, Eq. (3) is\n",
      "utilised to derive point-wise strain εs from the predicted displacement vector ds.\n",
      "Static Equilibrium Equations In nonlinear elasticity, σs predicted by hθh(Dk)\n",
      "at ps would be a 2nd Piola-Kirchhoff stress tensor, satisfy the following equilib-\n",
      "rium equation σs\n",
      "ji,j + Fi = 0 where (·),j is a shorthand for\n",
      "∂(·)\n",
      "∂(ps)j , Fi ∈R is the\n",
      "body force that is assumed to be zero at the static equilibrium, i and j denote\n",
      "three spatial directions. The PDEs that compose Lk\n",
      "S(θh; Dk) in Eqs. (1) and (2)\n",
      "are fstatic( ∂σs\n",
      "∂x , ∂σs\n",
      "∂y , ∂σs\n",
      "∂z ) = || ∂σs\n",
      "xx\n",
      "∂x +\n",
      "∂σs\n",
      "yx\n",
      "∂y\n",
      "+ ∂σs\n",
      "zx\n",
      "∂z ||2\n",
      "2 + ||\n",
      "∂σs\n",
      "xy\n",
      "∂x +\n",
      "∂σs\n",
      "yy\n",
      "∂y\n",
      "+\n",
      "∂σs\n",
      "zy\n",
      "∂z ||2\n",
      "2 +\n",
      "|| ∂σs\n",
      "xz\n",
      "∂x +\n",
      "∂σs\n",
      "yz\n",
      "∂y + ∂σs\n",
      "zz\n",
      "∂z ||2\n",
      "2.\n",
      "Nonlinear Constitutive Equations The stress and displacement gradients are\n",
      "further constrained by the constitutive equation as σs = µsJ−1\n",
      "s (FsFT\n",
      "s −I3×3) +\n",
      "λs(Js −1)I3×3, where Fs = I3×3 + ∂ds\n",
      "∂ps ∈R3×3 is the deformation gradient at ps,\n",
      "Js = det(Fs) ∈R is the determinant of Fs, λs ∈R and µs ∈R are Lame param-\n",
      "eters at ps which are computed with Young’s Modulus Es and Possion’s ratio vs\n",
      "using λs =\n",
      "Esνs\n",
      "(1−2νs)(1+νs) and µs =\n",
      "Es\n",
      "2(1+νs). The PDEs that comprise Lk\n",
      "C(θ; Dk) in\n",
      "Eqs. (1) and (2) are fconst(σs, ∂ds\n",
      "∂ps , λs, µs) = P\n",
      "i∈{1,2,3} ||σs\n",
      "ii −µsJ−1\n",
      "s ((FsFT\n",
      "s )ii −\n",
      "1) + λs(Js −1)||2\n",
      "2 + P\n",
      "⟨i,j⟩∈{⟨1,2⟩,⟨1,3⟩,⟨2,3⟩} ||σs\n",
      "ij −µsJ−1\n",
      "s (FsFT\n",
      "s )ij||2\n",
      "2, where to\n",
      "maintain uniformity of notations here σs\n",
      "11 = σs\n",
      "xx (similar for index pairs ⟨2, 2⟩\n",
      "and ⟨3, 3⟩) and σs\n",
      "12 = σs\n",
      "xy (similar for index pairs ⟨1, 3⟩and ⟨2, 3⟩) hold.\n",
      "Nonlinear Elastic Energy Density Function The elastic energy function\n",
      "fenergy(εs, λs, µs) that forms Lk\n",
      "E(θh; Dk) in Eqs. (1) and (2) is fenergy(εs, λs, µs) =\n",
      "µs\n",
      "2\n",
      "\u0010\n",
      "tr(FsFT\n",
      "s ) −3 −2 ln Js\n",
      "\u0011\n",
      "+ λs\n",
      "2\n",
      "\u0000Js −1\n",
      "\u00012\u0001\n",
      "with tr(FsFT\n",
      "s ) represented by εs.\n",
      "3\n",
      "Experiments and Results\n",
      "Data Sets and Evaluation Metrics The dataset contains Nk = 22 pairs of\n",
      "point sets generated over MRI-derived prostate meshes [2] by producing ground-\n",
      "truth deformations in [5.58, 8.66] mm using the finite element modelling (FEM)\n",
      "process, proposed in [6,21], with different material properties assigned to periph-\n",
      "eral zones (PZ) and transition zone (TZ): the ratios of Youngs’ Modulus with\n",
      "PZ and TZ\n",
      "EPZ\n",
      "k\n",
      "ETZ\n",
      "k\n",
      "were in the range of [0.10, 0.20]. All data was resampled to\n",
      "isotropic resolutions being 1 × 1 × 1 mm3. For each patient, the pairs of point\n",
      "Title Suppressed Due to Excessive Length\n",
      "7\n",
      "All Points\n",
      "Surface Points\n",
      "0.5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Root Mean Squared Error (mm)\n",
      "n. s.\n",
      "**\n",
      "*\n",
      "***\n",
      "*\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "*\n",
      "***\n",
      "**\n",
      "***\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "n. s.\n",
      "Without PINNs\n",
      "With PINNs, Linear Cfg1\n",
      "With PINNs, Linear Cfg2\n",
      "With PINNs, Nonlinear Cfg1\n",
      "With PINNs, Nonlinear Cfg2\n",
      "Fig. 2. The root-mean-squared-error (rmse) of registration using different algorithms\n",
      "for surface and all points on the left and right subplots, respectively. n.s.: not significant,\n",
      "⋆: p < 0.05, ⋆⋆: p < 0.01, ⋆⋆⋆: p < 0.001.\n",
      "Without PINNs\n",
      "Before Registration\n",
      "Linear Config1\n",
      "Linear Config2\n",
      "Nonlinear Config1\n",
      "Nonlinear Config2\n",
      "Case 1\n",
      "Case 2\n",
      "RMSE=2.98(3.24)                            \n",
      "RMSE=1.23(0.92)                            \n",
      "RMSE=0.56(0.53)                           \n",
      "RMSE=2.98(3.04)                            \n",
      "RMSE=1.21(1.04)                            \n",
      "RMSE=1.53(1.52)\n",
      "RMSE=1.56(1.55)                            \n",
      "RMSE=1.52(1.28)                            \n",
      "RMSE=0.58(0.57)                            \n",
      "RMSE=0.77(0.68)                            \n",
      "Fig. 3. Qualitative results for two cases with the five registration models. The rmse\n",
      "values for all points are also reported followed by those in parentheses for surface points.\n",
      "sets were randomly downsampled to PS and PT with Ns = Nt = 1024 and\n",
      "N surface\n",
      "s\n",
      "= N surface\n",
      "t\n",
      "= 512 independently. In the first experiment, the root-mean-\n",
      "square error (rmse) of registration was defined between predicted displacement\n",
      "and ground-truth Dgt\n",
      "S ∈R| e\n",
      "Ns|×3 as rmse =\n",
      "q\n",
      "1\n",
      "| e\n",
      "Ns|\n",
      "P\n",
      "s∈e\n",
      "Ns ||ds −dgt\n",
      "s ||2\n",
      "2 where\n",
      "here e\n",
      "Ns denote the set of all or surface points. In the second experiment, we\n",
      "computed the absolute percentage error (APE) as |(ratiopred −ratiogt)/ratiogt|\n",
      "for each case where ratiopred and ratiogt are predicted and ground-truth ratios,\n",
      "and also reported mean APE (mAPE) for all cases. Details about implementa-\n",
      "tions such as network architectures are in the Supplementary material.\n",
      "Registration Performances Fig. 2 includes the rmse values for all and sur-\n",
      "face points, respectively. Several key observations can be made from Fig. 2: (1)\n",
      "except for the case with Linear Cfg1 [14] for all points (p = 0.083), all methods\n",
      "outperformed Without PINNs significantly at α = 0.05 level; (2) except for the\n",
      "case where Linear Cfg1 and Linear Cfg2 were significantly different for all points\n",
      "(p = 0.0496), the differences between every pair of PINNs algorithms were not\n",
      "statistically significant; (3) Nonlinear Cfg2 achieved the lowest mean registration\n",
      "error values being 1.25 ± 0.62 mm and 1.24 ± 0.68 mm for both all and surface\n",
      "points (p < 0.001), against 1.80 ± 0.44 mm and 1.83 ± 0.51 mm Without PINNs.\n",
      "Fig. 3 shows the registration performances with two patient cases where blue\n",
      "8\n",
      "Z. Min et al.\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "Number of Epochs\n",
      "0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "Young's Modulus Ratio\n",
      "Case 1\n",
      "Linear\n",
      "Nonlinear\n",
      "Ground Truth\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "Number of Epochs\n",
      "0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "Young's Modulus Ratio\n",
      "Case 2\n",
      "Linear\n",
      "Nonlinear\n",
      "Ground Truth\n",
      "Fig. 4. The optimisation process of the inverse problem estimating the young’s modulus\n",
      "ratio between two sub-regions of prostate, are found by locating saddle points.\n",
      "Table 1. Young’s modulus ratio between the two regions estimated with two models.\n",
      "Patient ID Ground-truth\n",
      "Ratio\n",
      "Predicted Ratio\n",
      "Linear\n",
      "APE\n",
      "Linear\n",
      "Predicted Ratio\n",
      "Nonlinear\n",
      "APE\n",
      "Nonlinear\n",
      "Case 1\n",
      "0.19\n",
      "0.12\n",
      "36.84%\n",
      "0.19\n",
      "1.23%\n",
      "Case 2\n",
      "0.16\n",
      "0.10\n",
      "37.50%\n",
      "0.16\n",
      "1.25%\n",
      "Case 3\n",
      "0.11\n",
      "0.22\n",
      "100.00%\n",
      "0.10\n",
      "9.09%\n",
      "Case 4\n",
      "0.12\n",
      "0.22\n",
      "83.33%\n",
      "0.15\n",
      "25.00%\n",
      "Case 5\n",
      "0.17\n",
      "0\n",
      "100.00%\n",
      "0.19\n",
      "11.76%\n",
      "Case 6\n",
      "0.19\n",
      "0\n",
      "100.00%\n",
      "0.12\n",
      "36.84%\n",
      "and red dots respectively denote source (or predicted warped source) and target\n",
      "point sets with exact correspondences before (or after) registration. In Case 1,\n",
      "the linear model (e.g., rmse values were 0.56 mm and 0.53 mm for all and surface\n",
      "points using Linear Cfg2) was better than the nonlinear model (e.g., rmse values\n",
      "were 1.21 mm and 1.04 mm using Nonlinear Cfg2) and Without PINNs (i.e., rmse\n",
      "values were 2.98 mm and 3.24 mm), while nonlinear models outperformed linear\n",
      "ones and Without PINNs for Case 2. In the first row of Fig. 3, blue and red star\n",
      "shapes denote corresponding targets in two spaces.\n",
      "Results of the Inverse Problem Fig. 4 demonstrates that the ratios of young’s\n",
      "modulus between the PZ and TZ were recovered (only Cfg1s are reported due to\n",
      "much better performances than Cfg2s), by locating saddle points (i.e., through\n",
      "finding the flat line in Fig. 4) during optimisation. The confidence interval is\n",
      "represented as shadow area in Fig. 4. As shown in Fig. 4, the nonlinear model ex-\n",
      "hibited significant advantages which is expected because more subtle (i.e., high-\n",
      "order) information is preserved. Table 1 shows the ground-truth and predicted\n",
      "ratios for example cases, from which the APE was computed. The mAPE values\n",
      "with linear and nonlinear models were 76.28% ± 30.97% and 14.20% ± 14.12%\n",
      "respectively, indicating the nonlinear model performed better in the inverse prob-\n",
      "lem (p = 0.002).\n",
      "4\n",
      "Discussions and Conclusions\n",
      "We have demonstrated the success of incorporating the nonlinear elasticity in\n",
      "both forward and inverse problems of biomechanically constrained nonrigid point\n",
      "Title Suppressed Due to Excessive Length\n",
      "9\n",
      "set registration. This work needs to be interpreted with limitations. First, the\n",
      "drawn conclusions may not be directly generalizable given the limited data size.\n",
      "Second, although results shed light on tackling the inverse problem along with\n",
      "the registration, it requires additional efforts (e.g., adding regularization terms)\n",
      "to further improve both accuracy and success rate.\n",
      "To conclude, in this paper, we have utilised PINNs to solve both the registra-\n",
      "tion of soft tissues and the estimation of material properties, tackled as forward\n",
      "and inverse problems respectively, considering both linear and more complex\n",
      "nonlinear elasticities. Experimental results first show that no statistical signifi-\n",
      "cance is observed between linear and nonlinear models in the forward problem,\n",
      "among which results are highly variable across patients. The validity of adopt-\n",
      "ing PINNs for solving estimating parameters, together with the superiority of\n",
      "the nonlinear model, is also demonstrated. These conclusions are drawn based\n",
      "on clinical data from prostate cancer patients, for topical applications including\n",
      "intraoperative motion modelling and multimodal image registration, potentially,\n",
      "new applications in better characterisation of pathological tissue motion.\n",
      "Acknowledgments. This work was supported by the Wellcome/EPSRC Centre for\n",
      "Interventional and Surgical Sciences [203145Z/16/Z] and the International Alliance for\n",
      "Cancer Early Detection, an alliance between Cancer Research UK [C28070/A30912;\n",
      "C73666/A31378], Canary Center at Stanford University, the University of Cambridge,\n",
      "OHSU Knight Cancer Institute, University College London and the University of\n",
      "Manchester. This work was also supported in part by the National Natural Science\n",
      "Foundation of China under Grant 62303275.\n",
      "Disclosure of Interests. The authors have no competing interests to declare that\n",
      "are relevant to the content of this article.\n",
      "References\n",
      "1. Fu, Y., Lei, Y., Wang, T., Patel, P., Jani, A.B., Mao, H., Curran, W.J., Liu,\n",
      "T., Yang, X.: Biomechanically constrained non-rigid mr-trus prostate registration\n",
      "using deep learning based 3d point cloud matching. Medical image analysis 67,\n",
      "101845 (2021)\n",
      "2. Hamid, S., Donaldson, I.A., Hu, Y., Rodell, R., Villarini, B., Bonmati, E., Tran-\n",
      "ter, P., Punwani, S., Sidhu, H.S., Willis, S., et al.: The smarttarget biopsy trial:\n",
      "a prospective, within-person randomised, blinded trial comparing the accuracy of\n",
      "visual-registration and magnetic resonance imaging/ultrasound image-fusion tar-\n",
      "geted biopsies for prostate cancer risk stratification. European urology 75(5), 733–\n",
      "740 (2019)\n",
      "3. Hartmann, S., Gilbert, R.R.: Identifiability of material parameters in solid me-\n",
      "chanics. Archive of Applied Mechanics 88, 3–26 (2018)\n",
      "4. Holzapfel, G.A.: On large strain viscoelasticity: continuum formulation and finite\n",
      "element applications to elastomeric structures. International Journal for Numerical\n",
      "Methods in Engineering 39(22), 3903–3926 (1996)\n",
      "5. Hu, Y., Ahmed, H.U., Taylor, Z., Allen, C., Emberton, M., Hawkes, D., Barratt,\n",
      "D.: Mr to ultrasound registration for image-guided prostate interventions. Medical\n",
      "image analysis 16(3), 687–703 (2012)\n",
      "10\n",
      "Z. Min et al.\n",
      "6. Hu, Y., Carter, T.J., Ahmed, H.U., Emberton, M., Allen, C., Hawkes, D.J., Barratt,\n",
      "D.C.: Modelling prostate motion for data fusion during image-guided interventions.\n",
      "IEEE transactions on medical imaging 30(11), 1887–1900 (2011)\n",
      "7. Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati, E., Wang, G.,\n",
      "Bandula, S., Moore, C.M., Emberton, M., et al.: Weakly-supervised convolutional\n",
      "neural networks for multimodal image registration. Medical image analysis 49,\n",
      "1–13 (2018)\n",
      "8. Ji, Y., Ruan, L., Ren, W., Dun, G., Liu, J., Zhang, Y., Wan, Q.: Stiffness of prostate\n",
      "gland measured by transrectal real-time shear wave elastography for detection of\n",
      "prostate cancer: a feasibility study. The British journal of radiology 92(1097),\n",
      "20180970 (2019)\n",
      "9. Karniadakis, G.E., Kevrekidis, I.G., Lu, L., Perdikaris, P., Wang, S., Yang, L.:\n",
      "Physics-informed machine learning. Nature Reviews Physics 3(6), 422–440 (2021)\n",
      "10. Luo, J., Frisken, S., Wang, D., Golby, A., Sugiyama, M., Wells III, W.: Are registra-\n",
      "tion uncertainty and error monotonically associated? In: Medical Image Comput-\n",
      "ing and Computer Assisted Intervention–MICCAI 2020: 23rd International Con-\n",
      "ference, Lima, Peru, October 4–8, 2020, Proceedings, Part III 23. pp. 264–274.\n",
      "Springer (2020)\n",
      "11. Luo, J., Ma, G., Haouchine, N., Xu, Z., Wang, Y., Kapur, T., Ning, L., Wells,\n",
      "W.M., Frisken, S.: On the dataset quality control for image registration evaluation.\n",
      "In: International Conference on Medical Image Computing and Computer-Assisted\n",
      "Intervention. pp. 36–45. Springer (2022)\n",
      "12. Mihai, L.A., Goriely, A.: How to characterize a nonlinear elastic material? a review\n",
      "on nonlinear constitutive parameters in isotropic finite elasticity. Proceedings of\n",
      "the Royal Society A: Mathematical, Physical and Engineering Sciences 473(2207),\n",
      "20170607 (2017)\n",
      "13. Miller, K., Chinzei, K.: Mechanical properties of brain tissue in tension. Journal\n",
      "of biomechanics 35(4), 483–490 (2002)\n",
      "14. Min, Z., Baum, Z., Saeed, S.U., Emberton, M., Barratt, D.C., Taylor, Z.A., Hu,\n",
      "Y.: Non-rigid medical image registration using physics-informed neural networks.\n",
      "arXiv preprint arXiv:2302.10343 (2023)\n",
      "15. Nava, A., Mazza, E., Furrer, M., Villiger, P., Reinhart, W.: In vivo mechanical\n",
      "characterization of human liver. Medical image analysis 12(2), 203–216 (2008)\n",
      "16. Ogden, R.: Non-Linear Elastic Deformations. Courier Corporation (2013)\n",
      "17. Pfeiffer, M., Riediger, C., Leger, S., Kühn, J.P., Seppelt, D., Hoffmann, R.T.,\n",
      "Weitz, J., Speidel, S.: Non-rigid volume to surface registration using a data-driven\n",
      "biomechanical model. In: International Conference on Medical Image Computing\n",
      "and Computer-Assisted Intervention. pp. 724–734. Springer (2020)\n",
      "18. Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets\n",
      "for 3d classification and segmentation. In: Proceedings of the IEEE conference on\n",
      "computer vision and pattern recognition. pp. 652–660 (2017)\n",
      "19. Qin, C., Wang, S., Chen, C., Bai, W., Rueckert, D.: Generative myocardial motion\n",
      "tracking via latent space exploration with biomechanics-informed prior. Medical\n",
      "Image Analysis 83, 102682 (2023)\n",
      "20. Raissi, M., Perdikaris, P., Karniadakis, G.E.: Physics-informed neural networks:\n",
      "A deep learning framework for solving forward and inverse problems involving\n",
      "nonlinear partial differential equations. Journal of Computational physics 378,\n",
      "686–707 (2019)\n",
      "21. Saeed, S.U., Taylor, Z.A., Pinnock, M.A., Emberton, M., Barratt, D.C., Hu, Y.:\n",
      "Prostate motion modelling using biomechanically-trained deep neural networks on\n",
      "Title Suppressed Due to Excessive Length\n",
      "11\n",
      "unstructured nodes. In: International Conference on Medical Image Computing\n",
      "and Computer-Assisted Intervention. pp. 650–659. Springer (2020)\n",
      "22. Taylor, Z.A., Cheng, M., Ourselin, S.: High-speed nonlinear finite element analy-\n",
      "sis for surgical simulation using graphics processing units. IEEE transactions on\n",
      "medical imaging 27(5), 650–663 (2008)\n",
      "23. Taylor, Z.A., Comas, O., Cheng, M., Passenger, J., Hawkes, D.J., Atkinson, D.,\n",
      "Ourselin, S.: On modelling of anisotropic viscoelasticity for soft tissue simulation:\n",
      "Numerical solution and gpu execution. Medical image analysis 13(2), 234–244\n",
      "(2009)\n",
      "24. van de Ven, W.J., Hu, Y., Barentsz, J.O., Karssemeijer, N., Barratt, D., Huis-\n",
      "man, H.J.: Biomechanical modeling constrained surface-based image registration\n",
      "for prostate mr guided trus biopsy. Medical physics 42(5), 2470–2481 (2015)\n",
      "25. Wittek, A., Hawkins, T., Miller, K.: On the unimportance of constitutive mod-\n",
      "els in computing brain deformation for image-guided surgery. Biomechanics and\n",
      "modeling in mechanobiology 8, 77–84 (2009)\n",
      "26. Xu, Z., Luo, J., Lu, D., Yan, J., Frisken, S., Jagadeesan, J., Wells III, W.M.,\n",
      "Li, X., Zheng, Y., Tong, R.K.y.: Double-uncertainty guided spatial and temporal\n",
      "consistency regularization weighting for learning-based abdominal registration. In:\n",
      "Medical Image Computing and Computer Assisted Intervention–MICCAI 2022:\n",
      "25th International Conference, Singapore, September 18–22, 2022, Proceedings,\n",
      "Part VI. pp. 14–24. Springer (2022)\n",
      "27. Xu, Z., Luo, J., Yan, J., Li, X., Jayender, J.: F3rnet: full-resolution residual registra-\n",
      "tion network for deformable image registration. International journal of computer\n",
      "assisted radiology and surgery 16(6), 923–932 (2021)\n",
      "28. Zeng, Q., Fu, Y., Tian, Z., Lei, Y., Zhang, Y., Wang, T., Mao, H., Liu, T., Curran,\n",
      "W.J., Jani, A.B., et al.: Label-driven magnetic resonance imaging (mri)-transrectal\n",
      "ultrasound (trus) registration using weakly supervised learning for mri-guided\n",
      "prostate radiotherapy. Physics in Medicine & Biology 65(13), 135002 (2020)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# URL of the webpage containing PDF links\n",
    "webpage_url = 'https://arxiv.org/list/cs.CV/recent?skip=2&show=3'# i just giving only one paper to extract we can alter show=\n",
    "\n",
    "# Fetch webpage content\n",
    "response = requests.get(webpage_url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract the publication date\n",
    "date_element = soup.find('h3')\n",
    "publication_date = date_element.get_text(strip=True) if date_element else 'Unknown date'\n",
    "\n",
    "# Extract all titles, authors, and PDF URLs\n",
    "base_url = 'https://arxiv.org'\n",
    "papers = []\n",
    "\n",
    "# Find all entries\n",
    "entries = soup.find_all('dl')\n",
    "\n",
    "for entry in entries:\n",
    "    titles = entry.find_all('div', class_='list-title mathjax')\n",
    "    authors = entry.find_all('div', class_='list-authors')\n",
    "    pdf_links = entry.find_all('a', title='Download PDF')\n",
    "\n",
    "    for title, author, pdf_link in zip(titles, authors, pdf_links):\n",
    "        paper_title = title.get_text(strip=True).replace('Title:', '').strip()\n",
    "        paper_authors = [a.get_text(strip=True) for a in author.find_all('a')]\n",
    "        paper_pdf_url = base_url + pdf_link['href']\n",
    "        papers.append({\n",
    "            'title': paper_title,\n",
    "            'authors': paper_authors,\n",
    "            'pdf_url': paper_pdf_url,\n",
    "            'date': publication_date\n",
    "        })\n",
    "\n",
    "def extract_text_from_pdf(paper):\n",
    "    text = f\"publication date of {paper['title']}: {paper['date']}\\nTitle: {paper['title']}\\nAuthors of {paper['title']}: {', '.join(paper['authors'])}\\n\\n\"\n",
    "    try:\n",
    "        # Download PDF or directly process it\n",
    "        response = requests.get(paper['pdf_url'], stream=True)\n",
    "        document = fitz.open(stream=response.content, filetype=\"pdf\")\n",
    "\n",
    "        for page_num in range(len(document)):\n",
    "            page = document.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "\n",
    "    except Exception as e:\n",
    "        text += f\"Error processing PDF at {paper['pdf_url']}: {e}\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# Extract text from each PDF and print it along with title, authors, and date\n",
    "for paper in papers:\n",
    "    extracted_text = extract_text_from_pdf(paper)\n",
    "    print(extracted_text)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "extracted_texts=[extracted_text]\n",
    "# Split text into manageable chunks/documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    \n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=200, # Adjust overlap size based on requirements\n",
    ")\n",
    "\n",
    "documents = []\n",
    "for text in extracted_texts:\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    documents.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chaitanya\\anaconda34\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# Initialize the embeddings model from HuggingFace\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "# Create a FAISS vector store from documents and embeddings\n",
    "vector = FAISS.from_texts(documents, embeddings)\n",
    "# Create a retriever from the vector store\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "# Initialize the Ollama language model\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Initialize the output parser for string outputs\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# Define the system instruction for reformulating the user's question\n",
    "\n",
    "instruction_to_system = \"\"\"\n",
    "Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "# Create a prompt template for reformulating questions\n",
    "question_maker_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", instruction_to_system),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a chain that reformulates the question if needed\n",
    "question_chain = question_maker_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine if question needs reformulation based on chat history\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return question_chain\n",
    "    else:\n",
    "        return input[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Create a retriever chain to fetch relevant context for the question\n",
    "retriever_chain = RunnablePassthrough.assign(\n",
    "        context=contextualized_question | retriever #| format_docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt for the question-answering assistant\n",
    "qa_system_prompt =  \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer,dont hallicuniate i need concise answer . Do not generate your answer.\\\n",
    "{context}\"\"\"\n",
    "\n",
    "# Create a prompt template for the question-answering task\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Retrieval-Augmented Generation (RAG) chain\n",
    "rag_chain = (\n",
    "    retriever_chain\n",
    "    | qa_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, I can summarize the paper as follows:\n",
      "\n",
      "The paper discusses the application of Physics-Informed Neural Networks (PINNs) to solve the problem of identifying material properties in soft-tissue deformation modeling and image registration. The authors demonstrate that PINNs can be used to estimate material properties, such as Young's modulus, from incomplete and noisy data. They also highlight the challenges of image registration, where exact values of stress and strain are unknown, and boundary conditions need to be estimated.\n",
      "\n",
      "The paper appears to explore the use of PINNs in various biomedical applications, including soft-tissue deformation modeling and image registration, with a focus on identifying material properties and their importance in these fields.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"breif the paper what it is all about ??  \"\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "#Invoke the RAG chain with the question and chat history, and update chat history with responses\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg])\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###code to automate the scraping process everyday\n",
    "#import schedule\n",
    "#import time\n",
    "#import subprocess\n",
    "\n",
    "#def job():\n",
    "#    subprocess.run([\"python\", \"C:\\\\Path\\\\To\\\\YourScript\\\\scrape.py\"])\n",
    "\n",
    "#schedule.every().day.at(\"12:00\").do(job)\n",
    "\n",
    "#while True:\n",
    "#    schedule.run_pending()\n",
    "#    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Function to handle the chat interaction\n",
    "def chat_complete(message, state):\n",
    "    if state is None:\n",
    "        state = []\n",
    "    ai_msg = rag_chain.invoke({\"question\": message, \"chat_history\": state})\n",
    "    state.append({\"role\": \"user\", \"content\": message})\n",
    "    state.append({\"role\": \"assistant\", \"content\": ai_msg})\n",
    "    response = [(msg[\"content\"], state[i+1][\"content\"]) for i, msg in enumerate(state) if msg[\"role\"] == \"user\"]\n",
    "    return response, state\n",
    "\n",
    "# Define the Gradio interface\n",
    "with gr.Blocks() as block:\n",
    "    gr.Markdown(\"\"\"<h1><center> EduVisionBot </center></h1>\"\"\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    message = gr.Textbox(placeholder=\"Type your Message.........\")\n",
    "    state = gr.State([])\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    \n",
    "    submit.click(chat_complete, inputs=[message, state], outputs=[chatbot, state])\n",
    "block.launch(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
